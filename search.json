[
  {
    "objectID": "4511/hw1.html",
    "href": "4511/hw1.html",
    "title": "Homework One",
    "section": "",
    "text": "In this project, your Pacman agent will find paths through his maze world, both to reach a particular location and to collect food efficiently. You will build general search algorithms and apply them to Pacman scenarios.\nThis project includes an autograder for you to grade your answers on your machine. This can be run with the command:\npython autograder.py\nThe code for this project consists of several Python files, some of which you will need to read and understand in order to complete the assignment, and some of which you can ignore. You can download all the code and supporting files in: search.zip.\nFiles to Edit and Submit: You will fill in portions of search.py and searchAgents.py during the assignment. Once you have completed the assignment, you will submit these files to the submit server. Please submit a single (uncompressed) .tar containing these two files. The server will allow you to submit multiple times for credit, but please run the autograder locally first.\nEvaluation: Evaluation of your code’s correctness will be performed by the autograder. If you think your code is correct and the autograder is in error, bring this to my attention before the submission deadline. Point values are relative within each assignment: all assignments are scaled to 100 when calculating grades.\nAcademic Dishonesty: This assignment is individual effort. Please review the collaboration policy for the course and adhere to it.\n\n\n\n\n\n\n\n\nFiles you’ll edit:\n\n\n\nsearch.py\nWhere all of your search algorithms will reside.\n\n\nsearchAgents.py\nWhere all of your search-based agents will reside.\n\n\nFiles you might want to look at:\n\n\n\npacman.py\nThe main file that runs Pacman games. This file describes a Pacman GameState type, which you use in this project.\n\n\ngame.py\nThe logic behind how the Pacman world works. This file describes several supporting types like AgentState, Agent, Direction, and Grid.\n\n\nutil.py\nUseful data structures for implementing search algorithms.\n\n\nSupporting files you can ignore:\n\n\n\ngraphicsDisplay.py\nGraphics for Pacman\n\n\ngraphicsUtils.py\nSupport for Pacman graphics\n\n\ntextDisplay.py\nASCII graphics for Pacman\n\n\nghostAgents.py\nAgents to control ghosts\n\n\nkeyboardAgents.py\nKeyboard interfaces to control Pacman\n\n\nlayout.py\nCode for reading layout files and storing their contents\n\n\nautograder.py\nProject autograder\n\n\ntestParser.py\nParses autograder test and solution files\n\n\ntestClasses.py\nGeneral autograding test classes\n\n\ntest_cases/\nDirectory containing the test cases for each question\n\n\nsearchTestClasses.py\nProject 1 specific autograding test classes"
  },
  {
    "objectID": "4511/hw1.html#introduction",
    "href": "4511/hw1.html#introduction",
    "title": "Homework One",
    "section": "",
    "text": "In this project, your Pacman agent will find paths through his maze world, both to reach a particular location and to collect food efficiently. You will build general search algorithms and apply them to Pacman scenarios.\nThis project includes an autograder for you to grade your answers on your machine. This can be run with the command:\npython autograder.py\nThe code for this project consists of several Python files, some of which you will need to read and understand in order to complete the assignment, and some of which you can ignore. You can download all the code and supporting files in: search.zip.\nFiles to Edit and Submit: You will fill in portions of search.py and searchAgents.py during the assignment. Once you have completed the assignment, you will submit these files to the submit server. Please submit a single (uncompressed) .tar containing these two files. The server will allow you to submit multiple times for credit, but please run the autograder locally first.\nEvaluation: Evaluation of your code’s correctness will be performed by the autograder. If you think your code is correct and the autograder is in error, bring this to my attention before the submission deadline. Point values are relative within each assignment: all assignments are scaled to 100 when calculating grades.\nAcademic Dishonesty: This assignment is individual effort. Please review the collaboration policy for the course and adhere to it.\n\n\n\n\n\n\n\n\nFiles you’ll edit:\n\n\n\nsearch.py\nWhere all of your search algorithms will reside.\n\n\nsearchAgents.py\nWhere all of your search-based agents will reside.\n\n\nFiles you might want to look at:\n\n\n\npacman.py\nThe main file that runs Pacman games. This file describes a Pacman GameState type, which you use in this project.\n\n\ngame.py\nThe logic behind how the Pacman world works. This file describes several supporting types like AgentState, Agent, Direction, and Grid.\n\n\nutil.py\nUseful data structures for implementing search algorithms.\n\n\nSupporting files you can ignore:\n\n\n\ngraphicsDisplay.py\nGraphics for Pacman\n\n\ngraphicsUtils.py\nSupport for Pacman graphics\n\n\ntextDisplay.py\nASCII graphics for Pacman\n\n\nghostAgents.py\nAgents to control ghosts\n\n\nkeyboardAgents.py\nKeyboard interfaces to control Pacman\n\n\nlayout.py\nCode for reading layout files and storing their contents\n\n\nautograder.py\nProject autograder\n\n\ntestParser.py\nParses autograder test and solution files\n\n\ntestClasses.py\nGeneral autograding test classes\n\n\ntest_cases/\nDirectory containing the test cases for each question\n\n\nsearchTestClasses.py\nProject 1 specific autograding test classes"
  },
  {
    "objectID": "4511/hw1.html#welcome-to-pacman",
    "href": "4511/hw1.html#welcome-to-pacman",
    "title": "Homework One",
    "section": "2 Welcome to Pacman",
    "text": "2 Welcome to Pacman\nAfter downloading the code, unzipping it, and changing to the directory, you should be able to play a game of Pacman by typing the following at the command line:\npython pacman.py\nPacman lives in a shiny blue world of twisting corridors and tasty round treats. Navigating this world efficiently will be Pacman’s first step in mastering his domain.\nThe simplest agent in searchAgents.py is called the GoWestAgent, which always goes West (a trivial reflex agent). This agent can occasionally win:\npython pacman.py --layout testMaze --pacman GoWestAgent\nBut, things get ugly for this agent when turning is required:\npython pacman.py --layout tinyMaze --pacman GoWestAgent\nIf Pacman gets stuck, you can exit the game by typing CTRL-c into your terminal.\nSoon, your agent will solve not only tinyMaze, but any maze you want.\nNote that pacman.py supports a number of options that can each be expressed in a long way (e.g., --layout) or a short way (e.g., -l). You can see the list of all options and their default values via:\npython pacman.py -h"
  },
  {
    "objectID": "4511/hw1.html#new-syntax",
    "href": "4511/hw1.html#new-syntax",
    "title": "Homework One",
    "section": "3 New Syntax",
    "text": "3 New Syntax\nYou may not have encoutered Python type hints before:\ndef my_function(a: int, b: Tuple[int, int], c: List[List], d: Any, e: float=1.0):\nThis is annotating the type of the arguments that Python should expect for this function. In the example below, a should be an int, b should be a tuple of 2 ints, c should be a List of Lists of anything – therefore a 2D array of anything, d is essentially the same as not annotated and can by anything, and e should be a float. e is also set to 1.0 if nothing is passed in for it, i.e.:\nmy_function(1, (2, 3), [['a', 'b'], [None, my_class], [[]]], ('h', 1))\nThe above call fits the type annotations, and doesn’t pass anything in for e. Type annotations are meant to be an adddition to the docstrings to help you know what the functions are working with. Python itself doesn’t enforce these. Using them in your functions is optional."
  },
  {
    "objectID": "4511/hw1.html#q1-3-pts-depth-first-search",
    "href": "4511/hw1.html#q1-3-pts-depth-first-search",
    "title": "Homework One",
    "section": "4 Q1 (3 pts): Depth First Search",
    "text": "4 Q1 (3 pts): Depth First Search\n(3 pts) In searchAgents.py, you’ll find a fully implemented SearchAgent, which plans out a path through Pacman’s world and then executes that path step-by-step. The search algorithms for formulating a plan are not implemented – that’s your job.\nFirst, test that the SearchAgent is working correctly by running:\npython pacman.py -l tinyMaze -p SearchAgent -a fn=tinyMazeSearch\nThe command above tells the SearchAgent to use tinyMazeSearch as its search algorithm, which is implemented in search.py. Pacman should navigate the maze successfully.\nNow it’s time to write full-fledged generic search functions to help Pacman plan routes! Pseudocode for the search algorithms you’ll write can be found in the lecture slides. Remember that a search node must contain not only a state but also the information necessary to reconstruct the path (plan) which gets to that state.\nImportant note: All of your search functions need to return a list of actions that will lead the agent from the start to the goal. These actions all have to be legal moves (valid directions, no moving through walls).\nImportant note: Make sure to use the Stack, Queue and PriorityQueue data structures provided to you in util.py! These data structure implementations have particular properties which are required for compatibility with the autograder.\nHint: Each algorithm is very similar. Algorithms for DFS, BFS, UCS, and A* differ only in the details of how the fringe is managed. So, concentrate on getting DFS right and the rest should be relatively straightforward. Indeed, one possible implementation requires only a single generic search method which is configured with an algorithm-specific queuing strategy. (Your implementation need not be of this form to receive full credit).\nImplement the depth-first search (DFS) algorithm in the depthFirstSearch function in search.py. To make your algorithm complete, write the graph search version of DFS, which avoids expanding any already visited states.\nYour code should quickly find a solution for:\npython pacman.py -l tinyMaze -p SearchAgent\npython pacman.py -l mediumMaze -p SearchAgent\npython pacman.py -l bigMaze -z .5 -p SearchAgent\nThe Pacman board will show an overlay of the states explored, and the order in which they were explored (brighter red means earlier exploration). Is the exploration order what you would have expected? Does Pacman actually go to all the explored squares on his way to the goal?\nHint: If you use a Stack as your data structure, the solution found by your DFS algorithm for mediumMaze should have a length of 130 (provided you push successors onto the fringe in the order provided by getSuccessors; you might get 246 if you push them in the reverse order). Is this a least cost solution? If not, think about what depth-first search is doing wrong.\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q1"
  },
  {
    "objectID": "4511/hw1.html#q2-3-pts-breadth-first-search",
    "href": "4511/hw1.html#q2-3-pts-breadth-first-search",
    "title": "Homework One",
    "section": "5 Q2 (3 pts): Breadth First Search",
    "text": "5 Q2 (3 pts): Breadth First Search\nImplement the breadth-first search (BFS) algorithm in the breadthFirstSearch function in search.py. Again, write a graph search algorithm that avoids expanding any already visited states. Test your code the same way you did for depth-first search.\npython pacman.py -l mediumMaze -p SearchAgent -a fn=bfs\npython pacman.py -l bigMaze -p SearchAgent -a fn=bfs -z .5\nDoes BFS find a least cost solution? If not, check your implementation.\nHint: If Pacman moves too slowly for you, try the option –frameTime 0.\nNote: If you’ve written your search code generically, your code should work equally well for the eight-puzzle search problem without any changes.\npython eightpuzzle.py\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q2"
  },
  {
    "objectID": "4511/hw1.html#q3-3-pts-varying-the-cost-function",
    "href": "4511/hw1.html#q3-3-pts-varying-the-cost-function",
    "title": "Homework One",
    "section": "6 Q3 (3 pts): Varying the Cost Function",
    "text": "6 Q3 (3 pts): Varying the Cost Function\nWhile BFS will find a fewest-actions path to the goal, we might want to find paths that are “best” in other senses. Consider mediumDottedMaze and mediumScaryMaze.\nBy changing the cost function, we can encourage Pacman to find different paths. For example, we can charge more for dangerous steps in ghost-ridden areas or less for steps in food-rich areas, and a rational Pacman agent should adjust its behavior in response.\nImplement the uniform-cost graph search algorithm in the uniformCostSearch function in search.py. We encourage you to look through util.py for some data structures that may be useful in your implementation. You should now observe successful behavior in all three of the following layouts, where the agents below are all UCS agents that differ only in the cost function they use (the agents and cost functions are written for you):\npython pacman.py -l mediumMaze -p SearchAgent -a fn=ucs\npython pacman.py -l mediumDottedMaze -p StayEastSearchAgent\npython pacman.py -l mediumScaryMaze -p StayWestSearchAgent\nNote: You should get very low and very high path costs for the StayEastSearchAgent and StayWestSearchAgent respectively, due to their exponential cost functions (see searchAgents.py for details).\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q3"
  },
  {
    "objectID": "4511/hw1.html#q4-3-pts-a-search",
    "href": "4511/hw1.html#q4-3-pts-a-search",
    "title": "Homework One",
    "section": "7 Q4 (3 pts): A* search",
    "text": "7 Q4 (3 pts): A* search\nImplement A* graph search in the empty function aStarSearch in search.py. A* takes a heuristic function as an argument. Heuristics take two arguments: a state in the search problem (the main argument), and the problem itself (for reference information). The nullHeuristic heuristic function in search.py is a trivial example.\nYou can test your A* implementation on the original problem of finding a path through a maze to a fixed position using the Manhattan distance heuristic (implemented already as manhattanHeuristic in searchAgents.py).\npython pacman.py -l bigMaze -z .5 -p SearchAgent -a fn=astar,heuristic=manhattanHeuristic\nYou should see that A* finds the optimal solution slightly faster than uniform cost search (about 549 vs. 620 search nodes expanded in our implementation, but ties in priority may make your numbers differ slightly). What happens on openMaze for the various search strategies?\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q4"
  },
  {
    "objectID": "4511/hw1.html#q5-3-pts-finding-all-the-corners",
    "href": "4511/hw1.html#q5-3-pts-finding-all-the-corners",
    "title": "Homework One",
    "section": "8 Q5 (3 pts): Finding All the Corners",
    "text": "8 Q5 (3 pts): Finding All the Corners\nThe real power of A* will only be apparent with a more challenging search problem. Now, it’s time to formulate a new problem and design a heuristic for it.\nIn corner mazes, there are four dots, one in each corner. Our new search problem is to find the shortest path through the maze that touches all four corners (whether the maze actually has food there or not). Note that for some mazes like tinyCorners, the shortest path does not always go to the closest food first! Hint: the shortest path through tinyCorners takes 28 steps.\nNote: Make sure to complete Question 2 before working on Question 5, because Question 5 builds upon your answer for Question 2.\nImplement the CornersProblem search problem in searchAgents.py. You will need to choose a state representation that encodes all the information necessary to detect whether all four corners have been reached. Now, your search agent should solve:\npython pacman.py -l tinyCorners -p SearchAgent -a fn=bfs,prob=CornersProblem\npython pacman.py -l mediumCorners -p SearchAgent -a fn=bfs,prob=CornersProblem\nTo receive full credit, you need to define an abstract state representation that does not encode irrelevant information (like the position of ghosts, where extra food is, etc.). In particular, do not use a Pacman GameState as a search state. Your code will be very, very slow if you do (and also wrong).\nAn instance of the CornersProblem class represents an entire search problem, not a particular state. Particular states are returned by the functions you write, and your functions return a data structure of your choosing (e.g. tuple, set, etc.) that represents a state.\nFurthermore, while a program is running, remember that many states simultaneously exist, all on the queue of the search algorithm, and they should be independent of each other. In other words, you should not have only one state for the entire CornersProblem object; your class should be able to generate many different states to provide to the search algorithm.\nHint 1: The only parts of the game state you need to reference in your implementation are the starting Pacman position and the location of the four corners.\nHint 2: When coding up getSuccessors, make sure to add children to your successors list with a cost of 1.\nOur implementation of breadthFirstSearch expands just under 2000 search nodes on mediumCorners. However, heuristics (used with A* search) can reduce the amount of searching required.\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q5"
  },
  {
    "objectID": "4511/hw1.html#q6-3-pts-corners-problem-heuristic",
    "href": "4511/hw1.html#q6-3-pts-corners-problem-heuristic",
    "title": "Homework One",
    "section": "9 Q6 (3 pts): Corners Problem: Heuristic",
    "text": "9 Q6 (3 pts): Corners Problem: Heuristic\nNote: Make sure to complete Question 4 before working on Question 6, because Question 6 builds upon your answer for Question 4.\nImplement a non-trivial, consistent heuristic for the CornersProblem in cornersHeuristic.\npython pacman.py -l mediumCorners -p AStarCornersAgent -z 0.5\nNote: AStarCornersAgent is a shortcut for\n-p SearchAgent -a fn=aStarSearch,prob=CornersProblem,heuristic=cornersHeuristic\nAdmissibility vs. Consistency: Remember, heuristics are just functions that take search states and return numbers that estimate the cost to a nearest goal. More effective heuristics will return values closer to the actual goal costs. To be admissible, the heuristic values must be lower bounds on the actual shortest path cost to the nearest goal (and non-negative). To be consistent, it must additionally hold that if an action has cost c, then taking that action can only cause a drop in heuristic of at most c.\nRemember that admissibility isn’t enough to guarantee correctness in graph search – you need the stronger condition of consistency. However, admissible heuristics are usually also consistent, especially if they are derived from problem relaxations. Therefore it is usually easiest to start out by brainstorming admissible heuristics. Once you have an admissible heuristic that works well, you can check whether it is indeed consistent, too. The only way to guarantee consistency is with a proof. However, inconsistency can often be detected by verifying that for each node you expand, its successor nodes are equal or higher in in f-value. Moreover, if UCS and A* ever return paths of different lengths, your heuristic is inconsistent. This stuff is tricky!\nNon-Trivial Heuristics: The trivial heuristics are the ones that return zero everywhere (UCS) and the heuristic which computes the true completion cost. The former won’t save you any time, while the latter will timeout the autograder. You want a heuristic which reduces total compute time, though for this assignment the autograder will only check node counts (aside from enforcing a reasonable time limit).\nGrading: Your heuristic must be a non-trivial non-negative consistent heuristic to receive any points. Make sure that your heuristic returns 0 at every goal state and never returns a negative value. Depending on how few nodes your heuristic expands, you’ll be graded:\n\n\n\nNumber of nodes expanded\nGrade\n\n\n\n\nmore than 2000\n0/3\n\n\nat most 2000\n1/3\n\n\nat most 1600\n2/3\n\n\nat most 1200\n3/3\n\n\n\nRemember: If your heuristic is inconsistent, you will receive no credit, so be careful!\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q6"
  },
  {
    "objectID": "4511/hw1.html#q7-4-pts-eating-all-the-dots",
    "href": "4511/hw1.html#q7-4-pts-eating-all-the-dots",
    "title": "Homework One",
    "section": "10 Q7 (4 pts): Eating All The Dots",
    "text": "10 Q7 (4 pts): Eating All The Dots\nNow we’ll solve a hard search problem: eating all the Pacman food in as few steps as possible. For this, we’ll need a new search problem definition which formalizes the food-clearing problem: FoodSearchProblem in searchAgents.py (implemented for you). A solution is defined to be a path that collects all of the food in the Pacman world. For the present project, solutions do not take into account any ghosts or power pellets; solutions only depend on the placement of walls, regular food and Pacman. (Of course ghosts can ruin the execution of a solution! We’ll get to that in the next project.) If you have written your general search methods correctly, A* with a null heuristic (equivalent to uniform-cost search) should quickly find an optimal solution to testSearch with no code change on your part (total cost of 7).\npython pacman.py -l testSearch -p AStarFoodSearchAgent\nNote: AStarFoodSearchAgent is a shortcut for\n-p SearchAgent -a fn=astar,prob=FoodSearchProblem,heuristic=foodHeuristic\nYou should find that UCS starts to slow down even for the seemingly simple tinySearch. As a reference, our implementation takes 2.5 seconds to find a path of length 27 after expanding 5057 search nodes.\nNote: Make sure to complete Question 4 before working on Question 7, because Question 7 builds upon your answer for Question 4.\nFill in foodHeuristic in searchAgents.py with a consistent heuristic for the FoodSearchProblem. Try your agent on the trickySearch board:\npython pacman.py -l trickySearch -p AStarFoodSearchAgent\nOur UCS agent finds the optimal solution in about 13 seconds, exploring over 16,000 nodes.\nAny non-trivial non-negative consistent heuristic will receive 1 point. Make sure that your heuristic returns 0 at every goal state and never returns a negative value. Depending on how few nodes your heuristic expands, you’ll get additional points:\n\n\n\nNumber of nodes expanded\nGrade\n\n\n\n\nmore than 15000\n1/4\n\n\nat most 15000\n2/4\n\n\nat most 12000\n3/4\n\n\nat most 9000\n4/4 (full credit; medium)\n\n\nat most 7000\n5/4 (optional extra credit; hard)\n\n\n\nRemember: If your heuristic is inconsistent, you will receive no credit, so be careful! Can you solve mediumSearch in a short time? If so, we’re either very, very impressed, or your heuristic is inconsistent.\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q7"
  },
  {
    "objectID": "4511/hw1.html#q8-3-pts-suboptimal-search",
    "href": "4511/hw1.html#q8-3-pts-suboptimal-search",
    "title": "Homework One",
    "section": "11 Q8 (3 pts): Suboptimal Search",
    "text": "11 Q8 (3 pts): Suboptimal Search\nSometimes, even with A* and a good heuristic, finding the optimal path through all the dots is hard. In these cases, we’d still like to find a reasonably good path, quickly. In this section, you’ll write an agent that always greedily eats the closest dot. ClosestDotSearchAgent is implemented for you in searchAgents.py, but it’s missing a key function that finds a path to the closest dot.\nImplement the function findPathToClosestDot in searchAgents.py. Our agent solves this maze (suboptimally!) in under a second with a path cost of 350:\npython pacman.py -l bigSearch -p ClosestDotSearchAgent -z .5\nHint: The quickest way to complete findPathToClosestDot is to fill in the AnyFoodSearchProblem, which is missing its goal test. Then, solve that problem with an appropriate search function. The solution should be very short!\nYour ClosestDotSearchAgent won’t always find the shortest possible path through the maze. Make sure you understand why and try to come up with a small example where repeatedly going to the closest dot does not result in finding the shortest path for eating all the dots.\nGrading: Please run the below command to see if your implementation passes all the autograder test cases.\npython autograder.py -q q8"
  },
  {
    "objectID": "4511/03/03.html#announcements",
    "href": "4511/03/03.html#announcements",
    "title": "Local Search & Games",
    "section": "Announcements",
    "text": "Announcements\n\n\nHomework 1 is due on 15 September at 11:55 PM\n\nLate submission policy\n\nHomework 2 is due on 29 September at 11:55 PM\nFri 13 Sep Office Hours moved: 12 PM - 3 PM\nFri 20 Sep Office Hours moved: 12 PM - 3 PM"
  },
  {
    "objectID": "4511/03/03.html#why-are-we-here",
    "href": "4511/03/03.html#why-are-we-here",
    "title": "Local Search & Games",
    "section": "Why Are We Here?",
    "text": "Why Are We Here?"
  },
  {
    "objectID": "4511/03/03.html#why-are-we-here-1",
    "href": "4511/03/03.html#why-are-we-here-1",
    "title": "Local Search & Games",
    "section": "Why Are We Here?",
    "text": "Why Are We Here?\n\n⠀⠀⠀⠀⠀⠀⠀⢀⣠⣤⣤⣶⣶⣶⣶⣤⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⢀⣤⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣤⡀⠀⠀⠀⠀\n⠀⠀⠀⣴⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡄⠀⠀⠀\n⠀⢀⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠟⠁⠀⠀⠀\n⠀⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠟⠋⠀⠀⠀⠀⠀⠀\n⢠⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠟⠋            ⠀⣀⣄⡀      ⠀⠀⣠⣄⡀\n⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣏⠀⠀⠀            ⢸⣿⣿⣿      ⠀⢸⣿⣿⣿\n⠘⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣦⣀⠀            ⠉⠋⠁      ⠀⠀⠙⠋⠁\n⠀⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣦⡀⠀⠀⠀⠀⠀⠀\n⠀⠈⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣤⠀⠀⠀⠀\n⠀⠀⠀⠻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀\n⠀⠀⠀⠀⠈⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠛⠁⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠈⠙⠛⠛⠿⠿⠿⠿⠛⠛⠋⠁⠀⠀⠀⠀⠀⠀⠀"
  },
  {
    "objectID": "4511/03/03.html#search-why",
    "href": "4511/03/03.html#search-why",
    "title": "Local Search & Games",
    "section": "Search: Why?",
    "text": "Search: Why?\n\nFully-observed problem\nDeterministic actions and state\nWell-defined start and goal\n\n“Well-defined”"
  },
  {
    "objectID": "4511/03/03.html#goal-tests",
    "href": "4511/03/03.html#goal-tests",
    "title": "Local Search & Games",
    "section": "Goal Tests",
    "text": "Goal Tests"
  },
  {
    "objectID": "4511/03/03.html#goal-tests-1",
    "href": "4511/03/03.html#goal-tests-1",
    "title": "Local Search & Games",
    "section": "Goal Tests",
    "text": "Goal Tests"
  },
  {
    "objectID": "4511/03/03.html#best-first-search",
    "href": "4511/03/03.html#best-first-search",
    "title": "Local Search & Games",
    "section": "Best-First Search",
    "text": "Best-First Search"
  },
  {
    "objectID": "4511/03/03.html#a-search",
    "href": "4511/03/03.html#a-search",
    "title": "Local Search & Games",
    "section": "A* Search",
    "text": "A* Search\n\nInclude path-cost \\(g(n)\\)\n\n\\(f(n) = g(n) + h(n)\\)\n\n\n\n\n\n\nComplete (always)\nOptimal (sometimes)\nPainful \\(O(b^m)\\) time and space complexity"
  },
  {
    "objectID": "4511/03/03.html#a-vs.-dijkstra",
    "href": "4511/03/03.html#a-vs.-dijkstra",
    "title": "Local Search & Games",
    "section": "A* vs. Dijkstra",
    "text": "A* vs. Dijkstra"
  },
  {
    "objectID": "4511/03/03.html#choosing-heuristics",
    "href": "4511/03/03.html#choosing-heuristics",
    "title": "Local Search & Games",
    "section": "Choosing Heuristics",
    "text": "Choosing Heuristics\n\nRecall: \\(h(n)\\) estimates cost from \\(n\\) to goal\n\n\n\n\n\nAdmissibility\nConsistency"
  },
  {
    "objectID": "4511/03/03.html#choosing-heuristics-1",
    "href": "4511/03/03.html#choosing-heuristics-1",
    "title": "Local Search & Games",
    "section": "Choosing Heuristics",
    "text": "Choosing Heuristics\n\nAdmissibility\n\nNever overestimates cost from \\(n\\) to goal\nCost-optimal!\n\nConsistency\n\n\\(h(n) \\leq c(n, a, n') + h(n')\\)\n\\(n'\\) successors of \\(n\\)\n\\(c(n, a, n')\\) cost from \\(n\\) to \\(n'\\) given action \\(a\\)"
  },
  {
    "objectID": "4511/03/03.html#iterative-deepening-a-search",
    "href": "4511/03/03.html#iterative-deepening-a-search",
    "title": "Local Search & Games",
    "section": "Iterative-Deepening A* Search",
    "text": "Iterative-Deepening A* Search\n\n“IDA*” Search\n\nSimilar to Iterative Deepening with Depth-First Search\n\nDFS uses depth cutoff\nIDA* uses \\(h(n) + g(n)\\) cutoff with DFS\nOnce cutoff breached, new cutoff:\n\nTypically next-largest \\(h(n) + g(n)\\)\n\n\\(O(b^m)\\) time complexity 😔\n\\(O(d)\\) space complexity 😌"
  },
  {
    "objectID": "4511/03/03.html#beam-search",
    "href": "4511/03/03.html#beam-search",
    "title": "Local Search & Games",
    "section": "Beam Search",
    "text": "Beam Search\n\nBest-First Search:\n\nFrontier is all expanded nodes\n\nBeam Search:\n\n\\(k\\) “best” nodes are kept on frontier\n\nOthers discarded\n\nAlt: all nodes within \\(\\delta\\) of best node\nNot Optimal\nNot Complete"
  },
  {
    "objectID": "4511/03/03.html#recursive-best-first-search-rbfs",
    "href": "4511/03/03.html#recursive-best-first-search-rbfs",
    "title": "Local Search & Games",
    "section": "Recursive Best-First Search (RBFS)",
    "text": "Recursive Best-First Search (RBFS)\n\nNo \\(reached\\) table is kept\nSecond-best node \\(f(n)\\) retained\n\nSearch from each node cannot exceed this limit\nIf exceeded, recursion “backs up” to previous node\n\nMemory-efficient\n\nCan “cycle” between branches"
  },
  {
    "objectID": "4511/03/03.html#recursive-best-first-search-rbfs-1",
    "href": "4511/03/03.html#recursive-best-first-search-rbfs-1",
    "title": "Local Search & Games",
    "section": "Recursive Best-First Search (RBFS)",
    "text": "Recursive Best-First Search (RBFS)"
  },
  {
    "objectID": "4511/03/03.html#heuristic-characteristics",
    "href": "4511/03/03.html#heuristic-characteristics",
    "title": "Local Search & Games",
    "section": "Heuristic Characteristics",
    "text": "Heuristic Characteristics\n\nWhat makes a “good” heuristic?\n\nWe know about admissability and consistency\nWhat about performance?\n\nEffective branching factor\nEffective depth\n# of nodes expanded"
  },
  {
    "objectID": "4511/03/03.html#where-do-heuristics-come-from",
    "href": "4511/03/03.html#where-do-heuristics-come-from",
    "title": "Local Search & Games",
    "section": "Where Do Heuristics Come From?",
    "text": "Where Do Heuristics Come From?\n\nIntuition\n\n“Just Be Really Smart”\n\nRelaxation\n\nThe problem is constrained\nRemove the constraint\n\nPre-computation\n\nSub problems\n\nLearning"
  },
  {
    "objectID": "4511/03/03.html#what-even-is-the-goal",
    "href": "4511/03/03.html#what-even-is-the-goal",
    "title": "Local Search & Games",
    "section": "What Even Is The Goal?",
    "text": "What Even Is The Goal?\nUninformed/Informed Search:\n\nKnown start, known goal\nSearch for optimal path\n\nLocal Search:\n\n“Start” is irrelevant\nGoal is not known\n\nBut we know it when we see it\n\nSearch for goal"
  },
  {
    "objectID": "4511/03/03.html#brutal-example",
    "href": "4511/03/03.html#brutal-example",
    "title": "Local Search & Games",
    "section": "Brutal Example",
    "text": "Brutal Example"
  },
  {
    "objectID": "4511/03/03.html#less-brutal-example",
    "href": "4511/03/03.html#less-brutal-example",
    "title": "Local Search & Games",
    "section": "Less-Brutal Example",
    "text": "Less-Brutal Example"
  },
  {
    "objectID": "4511/03/03.html#real-world-examples",
    "href": "4511/03/03.html#real-world-examples",
    "title": "Local Search & Games",
    "section": "“Real-World” Examples",
    "text": "“Real-World” Examples\n\nScheduling\nLayout optimization\n\nFactories\nCircuits\n\nPortfolio management\nOthers?"
  },
  {
    "objectID": "4511/03/03.html#objective-function",
    "href": "4511/03/03.html#objective-function",
    "title": "Local Search & Games",
    "section": "Objective Function",
    "text": "Objective Function\n\nDo you know what you want?1\nCan you express it mathematically?2\n\nA single value\nMore is better\n\nObjective function: a function of state\n\nIf not, you might be humanIf not, you might be human"
  },
  {
    "objectID": "4511/03/03.html#hill-climbing",
    "href": "4511/03/03.html#hill-climbing",
    "title": "Local Search & Games",
    "section": "Hill-Climbing",
    "text": "Hill-Climbing\n\nObjective function\nState space mapping\n\nNeighbors"
  },
  {
    "objectID": "4511/03/03.html#hill-climbing-1",
    "href": "4511/03/03.html#hill-climbing-1",
    "title": "Local Search & Games",
    "section": "Hill-Climbing",
    "text": "Hill-Climbing"
  },
  {
    "objectID": "4511/03/03.html#the-hazards-of-climbing-hills",
    "href": "4511/03/03.html#the-hazards-of-climbing-hills",
    "title": "Local Search & Games",
    "section": "The Hazards of Climbing Hills",
    "text": "The Hazards of Climbing Hills\n\nLocal maxima\nPlateaus\nRidges"
  },
  {
    "objectID": "4511/03/03.html#five-queens",
    "href": "4511/03/03.html#five-queens",
    "title": "Local Search & Games",
    "section": "Five Queens",
    "text": "Five Queens"
  },
  {
    "objectID": "4511/03/03.html#five-queens-1",
    "href": "4511/03/03.html#five-queens-1",
    "title": "Local Search & Games",
    "section": "Five Queens",
    "text": "Five Queens"
  },
  {
    "objectID": "4511/03/03.html#five-queens-2",
    "href": "4511/03/03.html#five-queens-2",
    "title": "Local Search & Games",
    "section": "Five Queens",
    "text": "Five Queens"
  },
  {
    "objectID": "4511/03/03.html#variations",
    "href": "4511/03/03.html#variations",
    "title": "Local Search & Games",
    "section": "Variations",
    "text": "Variations\n\nSideways moves\n\nNot free\n\nStochastic moves\n\nFull set\nFirst choice\n\nRandom restarts\n\nIf at first you don’t succeed, you fail try again!\nComplete 😌"
  },
  {
    "objectID": "4511/03/03.html#the-trouble-with-local-maxima",
    "href": "4511/03/03.html#the-trouble-with-local-maxima",
    "title": "Local Search & Games",
    "section": "The Trouble with Local Maxima",
    "text": "The Trouble with Local Maxima\n\nWe don’t know that they’re local maxima\n\nUnless we do?\n\nHill climbing is efficient\n\nBut gets trapped\n\nExhaustive search is complete\n\nBut it’s exhaustive!\nStochastic methods are ‘exhaustive’"
  },
  {
    "objectID": "4511/03/03.html#simulated-annealing",
    "href": "4511/03/03.html#simulated-annealing",
    "title": "Local Search & Games",
    "section": "Simulated Annealing",
    "text": "Simulated Annealing"
  },
  {
    "objectID": "4511/03/03.html#simulated-annealing-1",
    "href": "4511/03/03.html#simulated-annealing-1",
    "title": "Local Search & Games",
    "section": "Simulated Annealing",
    "text": "Simulated Annealing\n\nDoesn’t actually have anything to do with metallurgy\nSearch begins with high “temperature”\n\nTemperature decreases during search\n\nNext state selected randomly\n\nImprovements always accepted\nNon-improvements rejected stochastically\nHigher temperature, less rejection\n“Worse” result, more rejection"
  },
  {
    "objectID": "4511/03/03.html#simulated-annealing-2",
    "href": "4511/03/03.html#simulated-annealing-2",
    "title": "Local Search & Games",
    "section": "Simulated Annealing",
    "text": "Simulated Annealing"
  },
  {
    "objectID": "4511/03/03.html#local-beam-search",
    "href": "4511/03/03.html#local-beam-search",
    "title": "Local Search & Games",
    "section": "Local Beam Search",
    "text": "Local Beam Search\nRecall:\n\nBeam search keeps track of \\(k\\) “best” branches\n\nLocal Beam Search:\n\nHill climbing search, keeping track of \\(k\\) successors\n\nDeterministic\nStochastic"
  },
  {
    "objectID": "4511/03/03.html#local-beam-search-1",
    "href": "4511/03/03.html#local-beam-search-1",
    "title": "Local Search & Games",
    "section": "Local Beam Search",
    "text": "Local Beam Search"
  },
  {
    "objectID": "4511/03/03.html#the-real-world-is-discrete",
    "href": "4511/03/03.html#the-real-world-is-discrete",
    "title": "Local Search & Games",
    "section": "The Real World Is Discrete",
    "text": "The Real World Is Discrete\n\n\n\n(it isn’t)"
  },
  {
    "objectID": "4511/03/03.html#the-real-world-is-not-discrete",
    "href": "4511/03/03.html#the-real-world-is-not-discrete",
    "title": "Local Search & Games",
    "section": "The Real World Is Not Discrete",
    "text": "The Real World Is Not Discrete\n\nDiscretize continuous space\n\nWorks iff no objective function discontinuities\nWhat happens if there are discontinuities?\nHow do we know that there are discontinuities?"
  },
  {
    "objectID": "4511/03/03.html#gradient-descent",
    "href": "4511/03/03.html#gradient-descent",
    "title": "Local Search & Games",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\nMinimize loss instead of climb hill\n\nStill the same idea\n\n\nConsider:\n\nOne state variable, \\(x\\)\nObjective function \\(f(x)\\)\n\nHow do we minimize \\(f(x)\\) ?\nIs there a closed form \\(\\frac{d}{dx}\\) ?"
  },
  {
    "objectID": "4511/03/03.html#gradient-descent-1",
    "href": "4511/03/03.html#gradient-descent-1",
    "title": "Local Search & Games",
    "section": "Gradient Descent",
    "text": "Gradient Descent\nMultivariate \\(\\vec{x} = x_0, x_1, ...\\)\n\n\nInstead of derivative, gradient:\n\\(\\nabla f(\\vec{x}) = \\left[ \\frac{\\partial f}{\\partial x_0}, \\frac{\\partial f}{\\partial x_1}, ...\\right]\\)\n\n\n“Locally” descend gradient:\n\\(\\vec{x} \\gets \\vec{x} + \\alpha \\nabla f(\\vec{x})\\)"
  },
  {
    "objectID": "4511/03/03.html#adversity",
    "href": "4511/03/03.html#adversity",
    "title": "Local Search & Games",
    "section": "Adversity",
    "text": "Adversity\nSo far:\n\nThe world does not care about us\nThis is a simplifying assumption!\n\nReality:\n\nThe world does not care us\n\n\n\n…but it wants things for “itself”\n\n\n\n\n…and we don’t want the same things"
  },
  {
    "objectID": "4511/03/03.html#the-adversary",
    "href": "4511/03/03.html#the-adversary",
    "title": "Local Search & Games",
    "section": "The Adversary",
    "text": "The Adversary\nOne extreme:\n\nSingle adversary\n\nAdversary wants the exact opposite from us\nIf adversary “wins,” we lose\n\n\n\n😐\n\n\nOther extreme:\n\nAn entire world of agents with different values\n\nThey might want some things similar to us\n\n“Economics”\n\n\n\n😐"
  },
  {
    "objectID": "4511/03/03.html#simple-games",
    "href": "4511/03/03.html#simple-games",
    "title": "Local Search & Games",
    "section": "Simple Games",
    "text": "Simple Games\n\nTwo-player\nTurn-taking\nDiscrete-state\nFully-observable\nZero-sum\n\nThis does some work for us!"
  },
  {
    "objectID": "4511/03/03.html#max-and-min",
    "href": "4511/03/03.html#max-and-min",
    "title": "Local Search & Games",
    "section": "Max and Min",
    "text": "Max and Min\n\nTwo players want the opposite of each other\nState takes into account both agents\n\nActions depend on whose turn it is"
  },
  {
    "objectID": "4511/03/03.html#minimax",
    "href": "4511/03/03.html#minimax",
    "title": "Local Search & Games",
    "section": "Minimax",
    "text": "Minimax\n\nInitial state \\(s_0\\)\nActions(\\(s\\)) and To-move(\\(s\\))\nResult(\\(s, a\\))\nIs-Terminal(\\(s\\))\nUtility(\\(s, p\\))"
  },
  {
    "objectID": "4511/03/03.html#minimax-1",
    "href": "4511/03/03.html#minimax-1",
    "title": "Local Search & Games",
    "section": "Minimax",
    "text": "Minimax"
  },
  {
    "objectID": "4511/03/03.html#minimax-2",
    "href": "4511/03/03.html#minimax-2",
    "title": "Local Search & Games",
    "section": "Minimax",
    "text": "Minimax"
  },
  {
    "objectID": "4511/03/03.html#more-than-two-players",
    "href": "4511/03/03.html#more-than-two-players",
    "title": "Local Search & Games",
    "section": "More Than Two Players",
    "text": "More Than Two Players\n\nTwo players, two values: \\(v_A, v_B\\)\n\nZero-sum: \\(v_A = -v_B\\)\nOnly one value needs to be explicitly represented\n\n\\(&gt; 2\\) players:\n\n\\(v_A, v_B, v_C ...\\)\nValue scalar becomes \\(\\vec{v}\\)"
  },
  {
    "objectID": "4511/03/03.html#society",
    "href": "4511/03/03.html#society",
    "title": "Local Search & Games",
    "section": "Society",
    "text": "Society\n\n\\(&gt;2\\) players, only one can win\nCooperation can be rational!\n\nExample:\n\nA & B: 30% win probability each\nC: 40% win probability\nA & B cooperate to eliminate C\n\n\\(\\rightarrow\\) A & B: 50% win probability each\n\n\n\n\n…what about friendship?"
  },
  {
    "objectID": "4511/03/03.html#minimax-efficiency",
    "href": "4511/03/03.html#minimax-efficiency",
    "title": "Local Search & Games",
    "section": "Minimax Efficiency",
    "text": "Minimax Efficiency\nPruning removes the need to explore the full tree.\n\nMax and Min nodes alternate\nOnce one value has been found, we can eliminate parts of search\n\nLower values, for Max\nHigher values, for Min\n\nRemember highest value (\\(\\alpha\\)) for Max\nRemember lowest value (\\(\\beta\\)) for Min"
  },
  {
    "objectID": "4511/03/03.html#pruning",
    "href": "4511/03/03.html#pruning",
    "title": "Local Search & Games",
    "section": "Pruning",
    "text": "Pruning"
  },
  {
    "objectID": "4511/03/03.html#heuristics",
    "href": "4511/03/03.html#heuristics",
    "title": "Local Search & Games",
    "section": "Heuristics 😌",
    "text": "Heuristics 😌\n\nIn practice, trees are far too deep to completely search\nHeuristic: replace utility with evaluation function\n\nBetter than losing, worse than winning\nRepresents chance of winning\n\nChance? 🎲🎲\n\nEven in deterministic games\nWhy?"
  },
  {
    "objectID": "4511/03/03.html#more-pruning",
    "href": "4511/03/03.html#more-pruning",
    "title": "Local Search & Games",
    "section": "More Pruning",
    "text": "More Pruning\n\nDon’t bother further searching bad moves\n\nExamples?\n\nBeam search\n\nLee Sedol’s singular win against AlphaGo"
  },
  {
    "objectID": "4511/03/03.html#other-techniques",
    "href": "4511/03/03.html#other-techniques",
    "title": "Local Search & Games",
    "section": "Other Techniques",
    "text": "Other Techniques\n\nMove ordering\n\nHow do we decide?\n\nLookup tables\n\nFor subsets of games"
  },
  {
    "objectID": "4511/03/03.html#monte-carlo-tree-search",
    "href": "4511/03/03.html#monte-carlo-tree-search",
    "title": "Local Search & Games",
    "section": "Monte Carlo Tree Search",
    "text": "Monte Carlo Tree Search\n\nMany games are too large even for an efficient \\(\\alpha\\)-\\(\\beta\\) search 😔\n\nWe can still play them\n\nSimulate plays of entire games from starting state\n\nUpdate win probability from each node (for each player) based on result\n\n“Explore/exploit” paradigm for move selection"
  },
  {
    "objectID": "4511/03/03.html#choosing-moves",
    "href": "4511/03/03.html#choosing-moves",
    "title": "Local Search & Games",
    "section": "Choosing Moves",
    "text": "Choosing Moves\n\nWe want our search to pick good moves\nWe want our search to pick unknown moves\nWe don’t want our search to pick bad moves\n\n(Assuming they’re actually bad moves)\n\n\nSelect moves based on a heuristic."
  },
  {
    "objectID": "4511/03/03.html#games-of-luck",
    "href": "4511/03/03.html#games-of-luck",
    "title": "Local Search & Games",
    "section": "Games of Luck",
    "text": "Games of Luck\n\nReal-world problems are rarely deterministic\nNon-deterministic state evolution:\n\nRoll a die to determine next position\nToss a coin to determine who picks candy first\nPrecise trajectory of kicked football1\nOthers?\n\n\nAny definition of “football”"
  },
  {
    "objectID": "4511/03/03.html#solving-non-deterministic-games",
    "href": "4511/03/03.html#solving-non-deterministic-games",
    "title": "Local Search & Games",
    "section": "Solving Non-Deterministic Games",
    "text": "Solving Non-Deterministic Games\nPreviously: Max and Min alternate turns\nNow:\n\nMax\nChance\nMin\nChance\n\n 😣"
  },
  {
    "objectID": "4511/03/03.html#expectiminimax",
    "href": "4511/03/03.html#expectiminimax",
    "title": "Local Search & Games",
    "section": "Expectiminimax",
    "text": "Expectiminimax\n\n“Expected value” of next position\n\n\n\n\n\nHow does this impact branching factor of the search?\n\n🫠"
  },
  {
    "objectID": "4511/03/03.html#expectiminimax-1",
    "href": "4511/03/03.html#expectiminimax-1",
    "title": "Local Search & Games",
    "section": "Expectiminimax",
    "text": "Expectiminimax"
  },
  {
    "objectID": "4511/03/03.html#filled-with-uncertainty",
    "href": "4511/03/03.html#filled-with-uncertainty",
    "title": "Local Search & Games",
    "section": "Filled With Uncertainty",
    "text": "Filled With Uncertainty\nWhat is to be done?\n\nPruning is still possible\n\nHow?\n\nHeuristic evaluation functions\n\nChoose carefully!"
  },
  {
    "objectID": "4511/03/03.html#non-optimal-adversaries",
    "href": "4511/03/03.html#non-optimal-adversaries",
    "title": "Local Search & Games",
    "section": "Non-Optimal Adversaries",
    "text": "Non-Optimal Adversaries\n\nIs deterministic “best” behavior optimal?\nAre all adversaries rational?\n\n\n\n\nExpectimax"
  },
  {
    "objectID": "4511/03/03.html#references",
    "href": "4511/03/03.html#references",
    "title": "Local Search & Games",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "4511/03/03.html#section-1",
    "href": "4511/03/03.html#section-1",
    "title": "Local Search & Games",
    "section": "",
    "text": "Stuart J. Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. 4th Edition, 2020.\nMykal Kochenderfer, Tim Wheeler, and Kyle Wray. Algorithms for Decision Making. 1st Edition, 2022.\nStanford CS231\nStanford CS228\nUC Berkeley CS188"
  },
  {
    "objectID": "4511/hw2.html",
    "href": "4511/hw2.html",
    "title": "Homework Two",
    "section": "",
    "text": "You will design agents for the classic version of Pacman, including ghosts. Along the way, you will implement both minimax and expectimax search and try your hand at evaluation function design.\nThe code base has not changed much from the previous assignment, but please start with a fresh installation, and don’t reuse files from Homework 1.\nWe provide the autograder for you to grade your answers locally. This can be run on all questions with the command:\npython autograder.py\nIt can be run for one particular question, such as q2, by:\npython autograder.py -q q2\nIt can be run for one particular test by commands of the form:\npython autograder.py -t test_cases/q2/0-small-tree\nBy default, the autograder displays graphics with the -t option, but doesn’t with the -q option. You can force graphics by using the --graphics flag, or force no graphics by using the --no-graphics flag.\nThe code for this assignment contains the following files in games dot zip.\n\n\n\n\n\n\n\nFiles you’ll edit:\n\n\n\nmultiAgents.py\nWhere all of your multi-agent search agents will reside.\n\n\nFiles you might want to look at:\n\n\n\npacman.py\nThe main file that runs Pacman games. This file also describes a Pacman GameState type, which you will use extensively in this assignment.\n\n\ngame.py\nThe logic behind how the Pacman world works. This file describes several supporting types like AgentState, Agent, Direction, and Grid.\n\n\nutil.py\nUseful data structures for implementing search algorithms. You don’t need to use these for this assignment, but may find other functions defined here to be useful.\n\n\nSupporting files you can ignore:\n\n\n\ngraphicsDisplay.py\nGraphics for Pacman\n\n\ngraphicsUtils.py\nSupport for Pacman graphics\n\n\ntextDisplay.py\nASCII graphics for Pacman\n\n\nghostAgents.py\nAgents to control ghosts\n\n\nkeyboardAgents.py\nKeyboard interfaces to control Pacman\n\n\nlayout.py\nCode for reading layout files and storing their contents\n\n\nautograder.py\nAutograder\n\n\ntestParser.py\nParses autograder test and solution files\n\n\ntestClasses.py\nGeneral autograding test classes\n\n\ntest_cases/\nDirectory containing the test cases for each question\n\n\nmultiagentTestClasses.py\nSpecific autograding test classes\n\n\n\nFiles to Edit and Submit: You will fill in portions of multiAgents.py during the assignment. Once you have completed the assignment, you will submit this files to the submit server. Please submit a single (uncompressed) .tar containing the file at the root of the tarball. The server will allow you to submit multiple times for credit, but please run the autograder locally first.\nEvaluation: Your code will be autograded for technical correctness. Please do not change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. However, the correctness of your implementation – not the autograder’s judgements – will be the final judge of your score. If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.\nAcademic Dishonesty: This assignment is individual effort. Please review the collaboration policy for the course and adhere to it."
  },
  {
    "objectID": "4511/hw2.html#introduction",
    "href": "4511/hw2.html#introduction",
    "title": "Homework Two",
    "section": "",
    "text": "You will design agents for the classic version of Pacman, including ghosts. Along the way, you will implement both minimax and expectimax search and try your hand at evaluation function design.\nThe code base has not changed much from the previous assignment, but please start with a fresh installation, and don’t reuse files from Homework 1.\nWe provide the autograder for you to grade your answers locally. This can be run on all questions with the command:\npython autograder.py\nIt can be run for one particular question, such as q2, by:\npython autograder.py -q q2\nIt can be run for one particular test by commands of the form:\npython autograder.py -t test_cases/q2/0-small-tree\nBy default, the autograder displays graphics with the -t option, but doesn’t with the -q option. You can force graphics by using the --graphics flag, or force no graphics by using the --no-graphics flag.\nThe code for this assignment contains the following files in games dot zip.\n\n\n\n\n\n\n\nFiles you’ll edit:\n\n\n\nmultiAgents.py\nWhere all of your multi-agent search agents will reside.\n\n\nFiles you might want to look at:\n\n\n\npacman.py\nThe main file that runs Pacman games. This file also describes a Pacman GameState type, which you will use extensively in this assignment.\n\n\ngame.py\nThe logic behind how the Pacman world works. This file describes several supporting types like AgentState, Agent, Direction, and Grid.\n\n\nutil.py\nUseful data structures for implementing search algorithms. You don’t need to use these for this assignment, but may find other functions defined here to be useful.\n\n\nSupporting files you can ignore:\n\n\n\ngraphicsDisplay.py\nGraphics for Pacman\n\n\ngraphicsUtils.py\nSupport for Pacman graphics\n\n\ntextDisplay.py\nASCII graphics for Pacman\n\n\nghostAgents.py\nAgents to control ghosts\n\n\nkeyboardAgents.py\nKeyboard interfaces to control Pacman\n\n\nlayout.py\nCode for reading layout files and storing their contents\n\n\nautograder.py\nAutograder\n\n\ntestParser.py\nParses autograder test and solution files\n\n\ntestClasses.py\nGeneral autograding test classes\n\n\ntest_cases/\nDirectory containing the test cases for each question\n\n\nmultiagentTestClasses.py\nSpecific autograding test classes\n\n\n\nFiles to Edit and Submit: You will fill in portions of multiAgents.py during the assignment. Once you have completed the assignment, you will submit this files to the submit server. Please submit a single (uncompressed) .tar containing the file at the root of the tarball. The server will allow you to submit multiple times for credit, but please run the autograder locally first.\nEvaluation: Your code will be autograded for technical correctness. Please do not change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. However, the correctness of your implementation – not the autograder’s judgements – will be the final judge of your score. If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.\nAcademic Dishonesty: This assignment is individual effort. Please review the collaboration policy for the course and adhere to it."
  },
  {
    "objectID": "4511/hw2.html#multi-agent-pacman",
    "href": "4511/hw2.html#multi-agent-pacman",
    "title": "Homework Two",
    "section": "2 Multi-Agent Pacman",
    "text": "2 Multi-Agent Pacman\nFirst, play a game of classic Pacman by running the following command:\npython pacman.py\nand using the arrow keys to move. Now, run the provided ReflexAgent in multiAgents.py\npython pacman.py -p ReflexAgent\nNote that it plays quite poorly even on simple layouts:\npython pacman.py -p ReflexAgent -l testClassic\nInspect its code (in multiAgents.py) and make sure you understand what it’s doing."
  },
  {
    "objectID": "4511/hw2.html#q1-4-pts-reflex-agent",
    "href": "4511/hw2.html#q1-4-pts-reflex-agent",
    "title": "Homework Two",
    "section": "3 Q1 (4 pts): Reflex Agent",
    "text": "3 Q1 (4 pts): Reflex Agent\nImprove the ReflexAgent in multiAgents.py to play respectably. The provided reflex agent code provides some helpful examples of methods that query the GameState for information. A capable reflex agent will have to consider both food locations and ghost locations to perform well. Your agent should easily and reliably clear the testClassic layout:\npython pacman.py -p ReflexAgent -l testClassic\nTry out your reflex agent on the default mediumClassic layout with one ghost or two (and animation off to speed up the display):\npython pacman.py --frameTime 0 -p ReflexAgent -k 1\npython pacman.py --frameTime 0 -p ReflexAgent -k 2\nHow does your agent fare? It will likely often die with 2 ghosts on the default board, unless your evaluation function is quite good.\nNote: Remember that newFood has the function asList()\nNote: As features, try the reciprocal of important values (such as distance to food) rather than just the values themselves.\nNote: The evaluation function you’re writing is evaluating state-action pairs; in later parts of the assignment, you’ll be evaluating states.\nNote: You may find it useful to view the internal contents of various objects for debugging. You can do this by printing the objects’ string representations. For example, you can print newGhostStates with print(newGhostStates).\nOptions: Default ghosts are random; you can also play for fun with slightly smarter directional ghosts using -g DirectionalGhost. If the randomness is preventing you from telling whether your agent is improving, you can use -f to run with a fixed random seed (same random choices every game). You can also play multiple games in a row with -n. Turn off graphics with -q to run lots of games quickly.\nGrading: We will run your agent on the openClassic layout 10 times. You will receive 0 points if your agent times out, or never wins. You will receive 1 point if your agent wins at least 5 times, or 2 points if your agent wins all 10 games. You will receive an additional 1 point if your agent’s average score is greater than 500, or 2 points if it is greater than 1000. You can try your agent out under these conditions with\npython autograder.py -q q1\nTo run it without graphics, use:\npython autograder.py -q q1 --no-graphics"
  },
  {
    "objectID": "4511/hw2.html#q2-5-pts-minimax",
    "href": "4511/hw2.html#q2-5-pts-minimax",
    "title": "Homework Two",
    "section": "4 Q2 (5 pts): Minimax",
    "text": "4 Q2 (5 pts): Minimax\nNow you will write an adversarial search agent in the provided MinimaxAgent class stub in multiAgents.py. Your minimax agent should work with any number of ghosts, so you’ll have to write an algorithm that is slightly more general than what you’ve previously seen in lecture. In particular, your minimax tree will have multiple min layers (one for each ghost) for every max layer.\nYour code should also expand the game tree to an arbitrary depth. Score the leaves of your minimax tree with the supplied self.evaluationFunction, which defaults to scoreEvaluationFunction. MinimaxAgent extends MultiAgentSearchAgent, which gives access to self.depth and self.evaluationFunction. Make sure your minimax code makes reference to these two variables where appropriate as these variables are populated in response to command line options.\nImportant: A single search ply is considered to be one Pacman move and all the ghosts’ responses, so depth 2 search will involve Pacman and each ghost moving two times (see diagram below).\n\n\n\nMinimax tree with depth 2\n\n\nGrading: We will be checking your code to determine whether it explores the correct number of game states. This is the only reliable way to detect some very subtle bugs in implementations of minimax. As a result, the autograder will be very picky about how many times you call GameState.generateSuccessor. If you call it any more or less than necessary, the autograder will complain. To test and debug your code, run\npython autograder.py -q q2\nThis will show what your algorithm does on a number of small trees, as well as a pacman game. To run it without graphics, use:\npython autograder.py -q q2 --no-graphics\n\n4.1 Hints and Observations\n\nImplement the algorithm recursively using helper function(s).\nThe correct implementation of minimax will lead to Pacman losing the game in some tests. This is not a problem: as it is correct behavior, it will pass the tests for full credit.\nThe evaluation function for the Pacman test in this part is already written (self.evaluationFunction). You shouldn’t change this function, but recognize that now we’re evaluating states rather than actions, as we were for the reflex agent. Look-ahead agents evaluate future states whereas reflex agents evaluate actions from the current state.\nThe minimax values of the initial state in the minimaxClassic layout are 9, 8, 7, -492 for depths 1, 2, 3 and 4 respectively. Note that your minimax agent will often win (665/1000 games for us) despite the dire prediction of depth 4 minimax.\n  python pacman.py -p MinimaxAgent -l minimaxClassic -a depth=4\nPacman is always agent 0, and the agents move in order of increasing agent index.\nAll states in minimax should be GameStates, either passed in to getAction or generated via GameState.generateSuccessor. You will not be abstracting to simplified states.\nOn larger boards such as openClassic and mediumClassic (the default), you’ll find Pacman to be good at not dying, but quite bad at winning. He’ll often thrash around without making progress. He might even thrash around right next to a dot without eating it because he doesn’t know where he’d go after eating that dot. Don’t worry if you see this behavior, question 5 will clean up all of these issues.\nWhen the Pacman believes that his death is unavoidable, he will try to end the game as soon as possible because of the constant penalty for living. Sometimes, this is the wrong thing to do with random ghosts, but minimax agents always assume the worst:\n  python pacman.py -p MinimaxAgent -l trappedClassic -a depth=3\nMake sure you understand why Pacman rushes the closest ghost in this case."
  },
  {
    "objectID": "4511/hw2.html#q3-5-pts-alpha-beta-pruning",
    "href": "4511/hw2.html#q3-5-pts-alpha-beta-pruning",
    "title": "Homework Two",
    "section": "5 Q3 (5 pts): Alpha-Beta Pruning",
    "text": "5 Q3 (5 pts): Alpha-Beta Pruning\nMake a new agent that uses alpha-beta pruning to more efficiently explore the minimax tree, in AlphaBetaAgent. Again, your algorithm will be slightly more general than the pseudocode from lecture, so part of the challenge is to extend the alpha-beta pruning logic appropriately to multiple minimizer agents.\nYou should see a speed-up (perhaps depth 3 alpha-beta will run as fast as depth 2 minimax). Ideally, depth 3 on smallClassic should run in just a few seconds per move or faster.\npython pacman.py -p AlphaBetaAgent -a depth=3 -l smallClassic\nThe AlphaBetaAgent minimax values should be identical to the MinimaxAgent minimax values, although the actions it selects can vary because of different tie-breaking behavior. Again, the minimax values of the initial state in the minimaxClassic layout are 9, 8, 7 and -492 for depths 1, 2, 3 and 4 respectively.\nGrading: Because we check your code to determine whether it explores the correct number of states, it is important that you perform alpha-beta pruning without reordering children. In other words, successor states should always be processed in the order returned by GameState.getLegalActions. Again, do not call GameState.generateSuccessor more than necessary.\nYou must not prune on equality in order to match the set of states explored by our autograder. (Indeed, alternatively, but incompatible with our autograder, would be to also allow for pruning on equality and invoke alpha-beta once on each child of the root node, but this will not match the autograder.)\nThe pseudo-code below represents the algorithm you should implement for this question. It varies from the reference implementation of Alpha-Beta pruning in the text/lecture by capturing more than two agents with a scalar value v (because the ghosts are all cooperating to defeat the Pacman).\n\n\n\\begin{algorithm} \\caption{Alpha-Beta Pruning} \\begin{algorithmic} \\Function{Max-Value}{$state, \\alpha, \\beta$} \\State $v \\gets -\\infty$ \\State $successors \\gets$ \\textsc{Expand}($state$) \\For{\\textbf{each} $s$ \\textbf{in} $successors$} \\State $v \\gets$ \\Call{Max}{$v$, \\textsc{Max-Value}($successor, \\alpha, \\beta$)} \\If{$v &gt; \\beta$} \\State \\textbf{return} $v$ \\EndIf \\State $\\alpha \\gets$ \\Call{Max}{$\\alpha, v$} \\EndFor \\State \\textbf{return} $v$ \\EndFunction \\State \\Function{Min-Value}{$state, \\alpha, \\beta$} \\State $v \\gets \\infty$ \\State $successors \\gets$ \\textsc{Expand}($state$) \\For{\\textbf{each} $s$ \\textbf{in} $successors$} \\State $v \\gets$ \\Call{Min}{$v$, \\textsc{Value}($successor, \\alpha, \\beta$)} \\If{$v &lt; \\alpha$} \\State \\textbf{return} $v$ \\EndIf \\State $\\beta \\gets$ \\Call{Min}{$\\beta, v$} \\EndFor \\State \\textbf{return} $v$ \\EndFunction \\State \\Function{Value}{$state, \\alpha, \\beta$} \\If{\\Call{NextAgent}{$state$} is $Max$} \\State \\textbf{return} \\Call{Max-Value}{$state, \\alpha, \\beta$} \\EndIf \\State \\textbf{return} \\Call{Min-Value}{$state, \\alpha, \\beta$} \\EndFunction \\end{algorithmic} \\end{algorithm}\n\n\nTo test and debug your code, run\npython autograder.py -q q3\nThis will show what your algorithm does on a number of small trees, as well as a pacman game. To run it without graphics, use:\npython autograder.py -q q3 --no-graphics\nThe correct implementation of alpha-beta pruning will lead to Pacman losing the game for some of the tests. This is not a problem: as it is correct behavior, you will earn full credit."
  },
  {
    "objectID": "4511/hw2.html#q4-5-pts-expectimax",
    "href": "4511/hw2.html#q4-5-pts-expectimax",
    "title": "Homework Two",
    "section": "6 Q4 (5 pts): Expectimax",
    "text": "6 Q4 (5 pts): Expectimax\nMinimax and alpha-beta are great, but they both assume that you are playing against an adversary who makes optimal decisions. As anyone who has ever won tic-tac-toe can tell you, this is not always the case. In this question you will implement the ExpectimaxAgent, which is useful for modeling probabilistic behavior of agents who may make suboptimal choices.\nAs with the search and problems yet to be covered in this class, the beauty of these algorithms is their general applicability. To expedite your own development, we’ve supplied some test cases based on generic trees. You can debug your implementation on small the game trees using the command:\npython autograder.py -q q4\nDebugging on these small and manageable test cases is recommended and will help you to find bugs quickly.\nOnce your algorithm is working on small trees, you can observe its success in Pacman. Random ghosts are of course not optimal minimax agents, and so modeling them with minimax search may not be appropriate. ExpectimaxAgent will no longer take the min over all ghost actions, but the expectation according to your agent’s model of how the ghosts act. To simplify your code, assume you will only be running against an adversary which chooses amongst their getLegalActions uniformly at random.\nTo see how the ExpectimaxAgent behaves in Pacman, run:\npython pacman.py -p ExpectimaxAgent -l minimaxClassic -a depth=3\nYou should now observe a more cavalier approach in close quarters with ghosts. In particular, if Pacman perceives that he could be trapped but might escape to grab a few more pieces of food, he’ll at least try. Investigate the results of these two scenarios:\npython pacman.py -p AlphaBetaAgent -l trappedClassic -a depth=3 -q -n 10\npython pacman.py -p ExpectimaxAgent -l trappedClassic -a depth=3 -q -n 10\nYou should find that your ExpectimaxAgent wins about half the time, while your AlphaBetaAgent always loses. Make sure you understand why the behavior here differs from the minimax case.\nThe correct implementation of expectimax will lead to Pacman losing some of the tests. This is not a problem: as it is correct behaviour, it will pass the tests."
  },
  {
    "objectID": "4511/hw2.html#q5-6-pts-evaluation-function",
    "href": "4511/hw2.html#q5-6-pts-evaluation-function",
    "title": "Homework Two",
    "section": "7 Q5 (6 pts): Evaluation Function",
    "text": "7 Q5 (6 pts): Evaluation Function\nWrite a better evaluation function for Pacman in the provided function betterEvaluationFunction. The evaluation function should evaluate states, rather than actions like your reflex agent evaluation function did. With depth 2 search, your evaluation function should clear the smallClassic layout with one random ghost more than half the time and still run at a reasonable rate (to get full credit, Pacman should be averaging around 1000 points when he’s winning).\nGrading: the autograder will run your agent on the smallClassic layout 10 times. We will assign points to your evaluation function in the following way:\n\nIf you win at least once without timing out the autograder, you receive 1 points. Any agent not satisfying these criteria will receive 0 points.\n+1 for winning at least 5 times, +2 for winning all 10 times\n+1 for an average score of at least 500, +2 for an average score of at least 1000 (including scores on lost games)\n+1 if your games take on average less than 30 seconds on the autograder machine, when run with --no-graphics.\nThe additional points for average score and computation time will only be awarded if you win at least 5 times.\nPlease do not copy any files from the previous assignment, as it will not pass the autograder on Gradescope.\n\nYou can try your agent out under these conditions with\npython autograder.py -q q5\nTo run it without graphics, use:\npython autograder.py -q q5 --no-graphics"
  },
  {
    "objectID": "advising.html",
    "href": "advising.html",
    "title": "Advising",
    "section": "",
    "text": "Undergraduate\nIf I am your undergraduate advisor, email and office hours are the most straightforward ways to discuss your questions.\n\n\nGraduate\nI am not currently soliciting applications, however any graduate student interested in collaborating is welcome to send me a proposal. It does not have to be particularly formal, however:\n\nTell me what questions you are interested in answering\nShow me what other work has been done in this avenue\nDiscuss a plan for executing your project\n\nI am fond of the Heilmeier Catechism, although it is not a perfect match for many kinds of academic research questions."
  },
  {
    "objectID": "teaching_writing.html",
    "href": "teaching_writing.html",
    "title": "Teaching and Writing",
    "section": "",
    "text": "Teaching\nCurrently:\n\nCSCI 1012 Intro. Programming in Python\n\nCourse Site\n\nCSCI 4511/5611 Artificial Intelligence Algorithms\n\nCourse Notes\n\n\nPreviously:\n\nCSCI 6366/4366 Neural Networks & Deep Learning\nCSCI 6531/4531 Computer Security\nCSCI 6917 Guided Research\nSEAS 6402 Data Analytics Capstone\n\nLectures:\n\nCSCI 1111 Intro. Software Development\nCSCI 4364/6364 Machine Learning\nMS&E 250A (Stanford) Risk Analysis\nMS&E 350 (Stanford) Risk Analysis Seminar\nAA 149 (Stanford) Operation of Aerospace Systems\n\n\n\nWriting\nK. Dobolyi, G. P. Sieniawski, D. Dobolyi, J. Goldfrank, and Z. Hampel-Arias, “Hindsight2020: Characterizing Uncertainty in the COVID-19 Scientific Literature,” Disaster Medicine and Public Health Preparedness, vol. 17, p. e437, 2023. doi:10.1017/dmp.2023.82\nJ. Goldfrank, M. E. Paté-Cornell, G. Forbes, and D. Liedtka, “Risk Reduction in Target Motion Analysis Using Approximate Dynamic Programming.” Military Operations Research, no. 1, 5–26, 2023 https://www.jstor.org/stable/27207613.\nL. Tindall, Z. Hampel-Arias, J. Goldfrank, E. Mair and T. Q. Nguven, ”Localizing Radio Frequency Targets Using Reinforcement Learning,” 2021 IEEE International Symposium on Robotic and Sensors Environments (ROSE), FL, USA, 2021, pp. 1-7, doi: 10.1109/ROSE52750.2021.9611756."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Office Hours\nAny GW student is welcome at my office hours. This schedule is up to date:\n\n\n\n\nDay\nTime\n\n\n\n\nMondays\n1:00 PM - 3:00 PM\n\n\nWednesdays\n12:30 PM - 3:00 PM\n\n\nFridays\n3:30 PM - 6 PM\n\n\nFriday 20 Sep 2024\n12:00-3:00 PM\n\n\n\n\n(Any struck through time indicates a deviation from the usual time.)\nThe location is typically SEH 4675, although I am often in the SEH 4th floor lobby area, as my office is small and windowless.\nYou are welcome to make an appointment. Appointments are not necessary, but will receive priority if you send an agenda at least 24 hours in advance.\nMy office can be slightly difficult to find:\n\nIt is on SEH 4th Floor, West wing\n\nExiting the elevators, make a right\nFrom the top of the stairs, go straight\n\nGo through the glass door (your card will work)\nMake a right where a right can be made, then an immediate left\nSEH 4675 will be on the left\n\n\n\nElectronic Mail\nMy address is joe.goldfrank@gwu.edu. My notes are typically short, direct, and polite; I encourage you to write to me in this way.\nLately there is a trend towards long formal notes, perhaps generated with some algorithm (many of them look the same). This style makes it harder for me to find your message amidst all the words.\nPlease refrain from sending me sales/marketing materials, I will mark these as spam."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joe Goldfrank",
    "section": "",
    "text": "Assistant Professor of Practice Department of Computer Science George Washington University\n\nI joined the GWU Department of Computer Science as a Visiting Professor in August 2022, and as an Assistant Professor of Practice in August 2023. You might read more about teaching and writing I have done.\nBefore this, I completed my PhD in Decision & Risk Analysis under the guidance of Elisabeth Paté-Cornell at Stanford University in California.\nSome years ago, I served on active duty in the U.S. Navy as a nuclear submarine line officer, and worked at the DOD Strategic Capabilities Office. I completed a B.S. (with honors) in Physics at the College of William and Mary in 2009.\nI am interested in improving the decisions that humans make. What that means is determined by each human.\nAdjacent to the university, I make acoustic, electric, and electronic music."
  },
  {
    "objectID": "4511/01/01.html#good-afternoon",
    "href": "4511/01/01.html#good-afternoon",
    "title": "AI Algorithms  Introduction",
    "section": "Good Afternoon",
    "text": "Good Afternoon"
  },
  {
    "objectID": "4511/01/01.html#how-to-succeed",
    "href": "4511/01/01.html#how-to-succeed",
    "title": "AI Algorithms  Introduction",
    "section": "How To Succeed",
    "text": "How To Succeed\n\nPay Attention\nStart Early\nDo The Work\n\nYourself"
  },
  {
    "objectID": "4511/01/01.html#extremely-important-dates",
    "href": "4511/01/01.html#extremely-important-dates",
    "title": "AI Algorithms  Introduction",
    "section": "Extremely Important Dates",
    "text": "Extremely Important Dates\nMidterm Exam: 16 October\n\nFinal Exam: 4 Dec\n\n\n\nArrange to be present for both exams."
  },
  {
    "objectID": "4511/01/01.html#grading",
    "href": "4511/01/01.html#grading",
    "title": "AI Algorithms  Introduction",
    "section": "Grading",
    "text": "Grading\n\n35% Homework average: weighted average of all homework\n\nLowest homework weighted 50%\n\n15% Project:\n\nOne intermediate deliverable\n\n50% Exam average: weighted average of two exams\n\nFinal replaces midterm if higher"
  },
  {
    "objectID": "4511/01/01.html#attendance",
    "href": "4511/01/01.html#attendance",
    "title": "AI Algorithms  Introduction",
    "section": "Attendance",
    "text": "Attendance\n\nOptional\nRecommended\nAssumed\nOffice Hours\n\nWhy are there so many?"
  },
  {
    "objectID": "4511/01/01.html#office-hours",
    "href": "4511/01/01.html#office-hours",
    "title": "AI Algorithms  Introduction",
    "section": "Office Hours",
    "text": "Office Hours\n\nMon 1:00-3:00 PM\nWeds 12:30 PM - 3:00 PM\nFri 3:00-6:00 PM\nAppointments are not necessary"
  },
  {
    "objectID": "4511/01/01.html#the-syllabus",
    "href": "4511/01/01.html#the-syllabus",
    "title": "AI Algorithms  Introduction",
    "section": "The Syllabus",
    "text": "The Syllabus\n\nHomework 0:\n\nSyllabus acknowledgement\nPython/autograder check\nMust be completed before you get credit for anything\nWrite it yourself"
  },
  {
    "objectID": "4511/01/01.html#write-it-yourself",
    "href": "4511/01/01.html#write-it-yourself",
    "title": "AI Algorithms  Introduction",
    "section": "Write It Yourself",
    "text": "Write It Yourself\n\nCopying code (from anywhere!) is generally prohibited, however:\n\nSearching for errors, use of Stack Overflow, etc. is allowed\nUse of code snippets from language documentation is allowed\nCollaborating to understand the algorithms is always allowed\n\nDocument what help you received when solving the problems\n\nYour code will almost certainly show up on your exam."
  },
  {
    "objectID": "4511/01/01.html#write-it-yourself-1",
    "href": "4511/01/01.html#write-it-yourself-1",
    "title": "AI Algorithms  Introduction",
    "section": "Write It Yourself",
    "text": "Write It Yourself\n\nI check my email and respond\nPlease do not use ChatGPT (etc.) to write emails to me\n\n“I hope this email finds you well”\n“I understand the importance of…”\n“I appreciate your time and attention to this matter”\n“I look forward to your response”\n\n\nIf nobody wrote it, why should anybody read it?"
  },
  {
    "objectID": "4511/01/01.html#textbook",
    "href": "4511/01/01.html#textbook",
    "title": "AI Algorithms  Introduction",
    "section": "Textbook",
    "text": "Textbook\nStuart J. Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. 4th Edition, 2020.\nSeveral copies will be on reserve at the GWU Library."
  },
  {
    "objectID": "4511/01/01.html#mechanics",
    "href": "4511/01/01.html#mechanics",
    "title": "AI Algorithms  Introduction",
    "section": "Mechanics",
    "text": "Mechanics\n\nOne 2.5 hr meeting per week\nExams in person\n\nPeriodic in-class practice\n\nHomework via submit server\nProgramming assignments in Python\n\nIf you don’t know Python: you will.\n\nRhythms"
  },
  {
    "objectID": "4511/01/01.html#do-we-even-need-to-introduce-ai",
    "href": "4511/01/01.html#do-we-even-need-to-introduce-ai",
    "title": "AI Algorithms  Introduction",
    "section": "Do We Even Need to Introduce AI?",
    "text": "Do We Even Need to Introduce AI?\n\nYou have undoubtedly used an LLM\n\nYou have almost certainly used speech-to-text\n\nYou may have ridden in a self-driving car\nYou probably unlock your telephone with your face\n\nConsider how this sentence would have been received in 1995\n\nYou trust software to give you street directions\nYou have probably flown on an airliner with autopilot\nYou might have lost to a computer at chess"
  },
  {
    "objectID": "4511/01/01.html#what-is-artificial-intelligence",
    "href": "4511/01/01.html#what-is-artificial-intelligence",
    "title": "AI Algorithms  Introduction",
    "section": "What Is Artificial Intelligence?",
    "text": "What Is Artificial Intelligence?\nWhat is intelligence?\n\nThought\nReasoning\nBehavior\n\nDo we need all three?\nDoes “AI” need all three?"
  },
  {
    "objectID": "4511/01/01.html#is-it-intelligent",
    "href": "4511/01/01.html#is-it-intelligent",
    "title": "AI Algorithms  Introduction",
    "section": "Is It Intelligent?",
    "text": "Is It Intelligent?\n\n\n\n\n\n\n\nImages: Speed Queen, Volvo"
  },
  {
    "objectID": "4511/01/01.html#rationality",
    "href": "4511/01/01.html#rationality",
    "title": "AI Algorithms  Introduction",
    "section": "Rationality",
    "text": "Rationality\n\nDecisions\nOutcomes\nValues\n\nIt is possible to make better decisions.\n\n\nRational agents make better decisions."
  },
  {
    "objectID": "4511/01/01.html#which-decision",
    "href": "4511/01/01.html#which-decision",
    "title": "AI Algorithms  Introduction",
    "section": "Which Decision?",
    "text": "Which Decision?\n\n\n\nPay $17 for this pizza, delivered\nPay $21 for the same pizza, delivered"
  },
  {
    "objectID": "4511/01/01.html#basically-the-same-problem",
    "href": "4511/01/01.html#basically-the-same-problem",
    "title": "AI Algorithms  Introduction",
    "section": "Basically The Same Problem",
    "text": "Basically The Same Problem\n\n\nImage: Bloomberg"
  },
  {
    "objectID": "4511/01/01.html#expected-utility",
    "href": "4511/01/01.html#expected-utility",
    "title": "AI Algorithms  Introduction",
    "section": "Expected Utility",
    "text": "Expected Utility\nWhich would you prefer?\n\nReceive $10\nFlip a fair coin:\n\nHeads - Pay $10\nTails - Receive $100\n\n\n\n\n\nMany outcomes aren’t directly expressed in dollars\nRational agents maximize expected utility"
  },
  {
    "objectID": "4511/01/01.html#defining-ai-again",
    "href": "4511/01/01.html#defining-ai-again",
    "title": "AI Algorithms  Introduction",
    "section": "Defining AI, Again",
    "text": "Defining AI, Again\n\nThought “vs.” Action\nHuman “vs.” Rational\nWhat is necessary?\n\nAll four combinations have been asserted"
  },
  {
    "objectID": "4511/01/01.html#errors",
    "href": "4511/01/01.html#errors",
    "title": "AI Algorithms  Introduction",
    "section": "Errors",
    "text": "Errors\n\nWhat happens when a human1 crashes a bicycle?\nWhat happens when a self-driving car2 crashes?\nWho is responsible when a self-driving car crashes?\n\n\n\nHow do “we” ensure AI values align with human values?\nHuman at faultSoftware at fault"
  },
  {
    "objectID": "4511/01/01.html#alignment",
    "href": "4511/01/01.html#alignment",
    "title": "AI Algorithms  Introduction",
    "section": "Alignment",
    "text": "Alignment\n\n\nImage: Meme; fair use."
  },
  {
    "objectID": "4511/01/01.html#alignment-1",
    "href": "4511/01/01.html#alignment-1",
    "title": "AI Algorithms  Introduction",
    "section": "Alignment",
    "text": "Alignment\n\nAre universal human values defined?\nHow are AI values defined?\nHow are AI values validated?\n\nThis is an open area of investigation.1\nAnd of concern."
  },
  {
    "objectID": "4511/01/01.html#how-we-got-here",
    "href": "4511/01/01.html#how-we-got-here",
    "title": "AI Algorithms  Introduction",
    "section": "How We Got Here",
    "text": "How We Got Here\n\n\nNeural Networks\n\nPerceptron (McCulloch & Pitts, 1943)\n“Computing Machinery and Intelligence” (Turing, 1950)\n\nLogic\n\nSamuel’s checkers, MANIAC Chess (1950s)\nDartmouth “Artificial Intelligence” conference (1956)\nMinsky & Papert assault perceptrons (1959)"
  },
  {
    "objectID": "4511/01/01.html#how-we-got-here-1",
    "href": "4511/01/01.html#how-we-got-here-1",
    "title": "AI Algorithms  Introduction",
    "section": "How We Got Here",
    "text": "How We Got Here\n\n\nKnowledge/Expert Systems\n\nExpert systems boom (1980s)\nBack propagation paper (Rumelhart et al., 1986)\nExpert systems bust (1990s)\n\nProbabilistic methods\n\nTD-Gammon (1992)\nDeep Blue defeats Kasparov (1997)"
  },
  {
    "objectID": "4511/01/01.html#how-we-got-here-2",
    "href": "4511/01/01.html#how-we-got-here-2",
    "title": "AI Algorithms  Introduction",
    "section": "How We Got Here",
    "text": "How We Got Here\n\n\nNeural Networks\n\nAlexNet computer vision (2012)\nDeepMind Atari (2013)\nAlphaGo defeats Sedol (2016)\nGoogle Translate LSTM (2016)\nAlphaFold (2018)\n\nLarge Language Models\n\nAttention Is All You Need (2017)\nGPT-3.5 (2022)"
  },
  {
    "objectID": "4511/01/01.html#where-do-we-go-now",
    "href": "4511/01/01.html#where-do-we-go-now",
    "title": "AI Algorithms  Introduction",
    "section": "Where Do We Go Now?",
    "text": "Where Do We Go Now?\n\nGame-playing\n\nReal-world tasks that look like games\n\nStatistical generation of text, images, video…\nOpen-ended logical problems\n\nUnsolved problems\n\nProblems with poorly-defined interfaces"
  },
  {
    "objectID": "4511/01/01.html#societal-implications",
    "href": "4511/01/01.html#societal-implications",
    "title": "AI Algorithms  Introduction",
    "section": "Societal Implications",
    "text": "Societal Implications\n\nTranslation\nText generation\n“Art” generation\nDecision-making\n\n“Who is responsible for…”"
  },
  {
    "objectID": "4511/01/01.html#what-this-course-is-not-about",
    "href": "4511/01/01.html#what-this-course-is-not-about",
    "title": "AI Algorithms  Introduction",
    "section": "What This Course Is Not About",
    "text": "What This Course Is Not About\n\nTranslation\nText generation\n“Art” generation"
  },
  {
    "objectID": "4511/01/01.html#what-this-course-is-about",
    "href": "4511/01/01.html#what-this-course-is-about",
    "title": "AI Algorithms  Introduction",
    "section": "What This Course Is About",
    "text": "What This Course Is About\n\nThe design of rational agents\nGeneral AI techniques for problem solving\n\nRecognizing when a new problem has an “existing” solution\n\nSolving problems approximately\n\nOptimal solutions often intractable"
  },
  {
    "objectID": "4511/01/01.html#the-rational-agent",
    "href": "4511/01/01.html#the-rational-agent",
    "title": "AI Algorithms  Introduction",
    "section": "The Rational Agent",
    "text": "The Rational Agent\n\nHas a utility function\n\nMaximizes expected utility\n\nSensors: perceives environment\nActuators: influences environment\n\nWhat is in between sensors and actuators?\nThe agent function."
  },
  {
    "objectID": "4511/01/01.html#reflex-agent",
    "href": "4511/01/01.html#reflex-agent",
    "title": "AI Algorithms  Introduction",
    "section": "Reflex Agent",
    "text": "Reflex Agent\n\n\n\nVery basic form of agent function\nPercept \\(\\rightarrow\\) Action lookup table\nGood for simple games\n\nTic-tac-toe\nCheckers?\n\nNeeds entire state space in table"
  },
  {
    "objectID": "4511/01/01.html#state-space-size",
    "href": "4511/01/01.html#state-space-size",
    "title": "AI Algorithms  Introduction",
    "section": "State Space Size",
    "text": "State Space Size\n\n\n\nTic-tac-toe: \\(10^3\\)\nCheckers: \\(10^{20}\\)\nChess: \\(10^{44}\\)\nGo: \\(10^{170}\\)\nSelf-driving car: ?"
  },
  {
    "objectID": "4511/01/01.html#partially-observable-state",
    "href": "4511/01/01.html#partially-observable-state",
    "title": "AI Algorithms  Introduction",
    "section": "Partially-Observable State",
    "text": "Partially-Observable State"
  },
  {
    "objectID": "4511/01/01.html#partially-observable-state-1",
    "href": "4511/01/01.html#partially-observable-state-1",
    "title": "AI Algorithms  Introduction",
    "section": "Partially-Observable State",
    "text": "Partially-Observable State\n\nMost real-world problems\n\nSensor error\nModel error\n\nReflex agents fail1\nAgent needs a belief state\n\nUnless total number of partial observations is bounded"
  },
  {
    "objectID": "4511/01/01.html#backing-up",
    "href": "4511/01/01.html#backing-up",
    "title": "AI Algorithms  Introduction",
    "section": "Backing Up",
    "text": "Backing Up\n\nThe Environment\n\nState Space\n\nRational Agents:\n\nSensors\nActuators\n\nSensors + State Space = Belief State\n\nFeatures of the problem are pre-defined; we define the agent function."
  },
  {
    "objectID": "4511/01/01.html#high-level-topics",
    "href": "4511/01/01.html#high-level-topics",
    "title": "AI Algorithms  Introduction",
    "section": "High-Level Topics",
    "text": "High-Level Topics\n\nSearch & Planning\nMulti-Agent Problems\nProbability & Inference\nLearning"
  },
  {
    "objectID": "4511/01/01.html#search-planning",
    "href": "4511/01/01.html#search-planning",
    "title": "AI Algorithms  Introduction",
    "section": "Search & Planning",
    "text": "Search & Planning\n\nWorld model\n\n“Fully known”\n\nHow do we accomplish a goal?"
  },
  {
    "objectID": "4511/01/01.html#multi-agent-problems",
    "href": "4511/01/01.html#multi-agent-problems",
    "title": "AI Algorithms  Introduction",
    "section": "Multi-Agent Problems",
    "text": "Multi-Agent Problems\n\nOther agents with different utility functions\nAgents react to our agent\nHow do we maximize our own utility?"
  },
  {
    "objectID": "4511/01/01.html#probability-inference",
    "href": "4511/01/01.html#probability-inference",
    "title": "AI Algorithms  Introduction",
    "section": "Probability & Inference",
    "text": "Probability & Inference\n\nPartially-observed states\nStochastic actions\nHow do we maintain a belief state?\nHow do we maximize our utility?"
  },
  {
    "objectID": "4511/01/01.html#learning",
    "href": "4511/01/01.html#learning",
    "title": "AI Algorithms  Introduction",
    "section": "Learning",
    "text": "Learning\n\nInitially-unknown problem structure\nExplore vs. exploit\n\nActions tell us more about the problem\nActions have some cost\n\nCan also learn from data"
  },
  {
    "objectID": "4511/01/01.html#big-picture",
    "href": "4511/01/01.html#big-picture",
    "title": "AI Algorithms  Introduction",
    "section": "Big Picture",
    "text": "Big Picture\n\nRepresent problems\n\nStates, actions\n\nImplement algorithms\nTrain (if needed) using data"
  },
  {
    "objectID": "4511/01/01.html#the-pac-man",
    "href": "4511/01/01.html#the-pac-man",
    "title": "AI Algorithms  Introduction",
    "section": "The Pac-Man",
    "text": "The Pac-Man\n\n\nNote that Bandai Namco Entertainment Inc. owns the trademark to “PAC-MAN” for Coin and Non-Coin Operated Electronic Amusement Apparatus for Playing a Game on a Video Output Display, as well as for Entertainment, namely providing a computer game that may be accessed network-wide by network users via mobile phones and computers; providing computer games via network between communications networks and computers. Our use is educational."
  },
  {
    "objectID": "4511/01/01.html#why-pac-man",
    "href": "4511/01/01.html#why-pac-man",
    "title": "AI Algorithms  Introduction",
    "section": "Why Pac-Man?",
    "text": "Why Pac-Man?\n\nReal world AI problems are hard\n\nThis is a one-semester course\n\nAlgorithms themselves are reasonably simple\n\nApplying them to problems is “the” problem\n\nPac-man is simple\nYou don’t have to like games\n\nSame algorithms apply to real world"
  },
  {
    "objectID": "4511/01/01.html#the-real-world",
    "href": "4511/01/01.html#the-real-world",
    "title": "AI Algorithms  Introduction",
    "section": "The Real World",
    "text": "The Real World\n\nObservable?\nDeterministic?\nMarkov?\nStatic?\nDiscrete?\n\nExamples…"
  },
  {
    "objectID": "4511/01/01.html#references",
    "href": "4511/01/01.html#references",
    "title": "AI Algorithms  Introduction",
    "section": "References",
    "text": "References\n\nStuart J. Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. 4th Edition, 2020.\nStanford CS231\nUC Berkeley CS188"
  },
  {
    "objectID": "4511/index.html",
    "href": "4511/index.html",
    "title": "CSCI 4511/6511 Fall 2024",
    "section": "",
    "text": "Syllabus"
  },
  {
    "objectID": "4511/index.html#notes",
    "href": "4511/index.html#notes",
    "title": "CSCI 4511/6511 Fall 2024",
    "section": "Notes",
    "text": "Notes\n\nLecture 1 - 28 Aug\nLecture 2 - 04 Sep\nLecture 3 - 11 Sep PDF"
  },
  {
    "objectID": "4511/index.html#homework",
    "href": "4511/index.html#homework",
    "title": "CSCI 4511/6511 Fall 2024",
    "section": "Homework",
    "text": "Homework\n\nHomework One\nHomework Two"
  },
  {
    "objectID": "4511/02/02.html#good-afternoon",
    "href": "4511/02/02.html#good-afternoon",
    "title": "Search",
    "section": "Good Afternoon",
    "text": "Good Afternoon\n\nGood afternoon"
  },
  {
    "objectID": "4511/02/02.html#announcements",
    "href": "4511/02/02.html#announcements",
    "title": "Search",
    "section": "Announcements",
    "text": "Announcements\n\nHomework 1 is due on 15 September at 11:55 PM\n\nAutomatic extensions"
  },
  {
    "objectID": "4511/02/02.html#why-are-we-here",
    "href": "4511/02/02.html#why-are-we-here",
    "title": "Search",
    "section": "Why Are We Here?",
    "text": "Why Are We Here?\n\nWe’re designing rational agents!\n\nPerception\nLogic\nAction"
  },
  {
    "objectID": "4511/02/02.html#in-practice",
    "href": "4511/02/02.html#in-practice",
    "title": "Search",
    "section": "In Practice",
    "text": "In Practice\n\nEnvironment\n\nWhat happens next\n\nPerception\n\nWhat agent can see\n\nAction\n\nWhat agent can do\n\nMeasure/Reward\n\nEncoded utility function"
  },
  {
    "objectID": "4511/02/02.html#search-why",
    "href": "4511/02/02.html#search-why",
    "title": "Search",
    "section": "Search: Why?",
    "text": "Search: Why?\n\nFully-observed problem\nDeterministic actions and state\nWell defined start and goal"
  },
  {
    "objectID": "4511/02/02.html#state",
    "href": "4511/02/02.html#state",
    "title": "Search",
    "section": "State",
    "text": "State\nWhat is the state space?"
  },
  {
    "objectID": "4511/02/02.html#state-1",
    "href": "4511/02/02.html#state-1",
    "title": "Search",
    "section": "State",
    "text": "State"
  },
  {
    "objectID": "4511/02/02.html#other-applications",
    "href": "4511/02/02.html#other-applications",
    "title": "Search",
    "section": "Other Applications",
    "text": "Other Applications\n\nRoute planning\nProtein design\nRobotic navigation\nScheduling\n\nScience\nManufacturing"
  },
  {
    "objectID": "4511/02/02.html#not-included",
    "href": "4511/02/02.html#not-included",
    "title": "Search",
    "section": "Not Included",
    "text": "Not Included\n\nUncertainty\n\nState transitions known\n\nAdversary\n\nNobody wants us to lose\n\nCooperation\nContinuous state"
  },
  {
    "objectID": "4511/02/02.html#who-is-the-pac-man",
    "href": "4511/02/02.html#who-is-the-pac-man",
    "title": "Search",
    "section": "Who Is The Pac-Man?",
    "text": "Who Is The Pac-Man?"
  },
  {
    "objectID": "4511/02/02.html#search-problem",
    "href": "4511/02/02.html#search-problem",
    "title": "Search",
    "section": "Search Problem",
    "text": "Search Problem\n\n\nSearch problem includes:\n\nStart State\nState Space\nState Transitions\nGoal Test\n\n\n\nState Space:\n\n\n\nActions & Successor States:"
  },
  {
    "objectID": "4511/02/02.html#tour-of-croatia",
    "href": "4511/02/02.html#tour-of-croatia",
    "title": "Search",
    "section": "Tour of Croatia",
    "text": "Tour of Croatia"
  },
  {
    "objectID": "4511/02/02.html#tour-of-croatia-1",
    "href": "4511/02/02.html#tour-of-croatia-1",
    "title": "Search",
    "section": "Tour of Croatia",
    "text": "Tour of Croatia"
  },
  {
    "objectID": "4511/02/02.html#state-space-size",
    "href": "4511/02/02.html#state-space-size",
    "title": "Search",
    "section": "State Space Size?",
    "text": "State Space Size?\n\n\nPacman positions, Wall Positions\nFood positions, Food Status?\nGhost positions, Ghost Status?"
  },
  {
    "objectID": "4511/02/02.html#state-space-graph",
    "href": "4511/02/02.html#state-space-graph",
    "title": "Search",
    "section": "State Space Graph",
    "text": "State Space Graph"
  },
  {
    "objectID": "4511/02/02.html#search-trees",
    "href": "4511/02/02.html#search-trees",
    "title": "Search",
    "section": "Search Trees",
    "text": "Search Trees\n\nGraph:\n\n\n\nTree:"
  },
  {
    "objectID": "4511/02/02.html#node-representation",
    "href": "4511/02/02.html#node-representation",
    "title": "Search",
    "section": "Node Representation",
    "text": "Node Representation\n\nGraph:\n\n\n\nTree:"
  },
  {
    "objectID": "4511/02/02.html#lets-talk-about-trees",
    "href": "4511/02/02.html#lets-talk-about-trees",
    "title": "Search",
    "section": "Let’s Talk About Trees",
    "text": "Let’s Talk About Trees\n\nFor any non-trivial problem, they’re big\n\n(Effective) branching factor\nDepth\n\nGraph and tree both too large for memory\n\nSuccessor function (graph)\nExpansion function (tree)"
  },
  {
    "objectID": "4511/02/02.html#how-to-solve-it",
    "href": "4511/02/02.html#how-to-solve-it",
    "title": "Search",
    "section": "How To Solve It",
    "text": "How To Solve It\n\nGiven:\n\nStarting node\nGoal test\nExpansion\n\nDo:\n\nExpand nodes from start\nTest each new node for goal\n\nIf goal, success\n\nExpand new nodes\n\nIf nothing left to expand, failure"
  },
  {
    "objectID": "4511/02/02.html#best-first-search",
    "href": "4511/02/02.html#best-first-search",
    "title": "Search",
    "section": "Best-First Search",
    "text": "Best-First Search"
  },
  {
    "objectID": "4511/02/02.html#frontier-expansion",
    "href": "4511/02/02.html#frontier-expansion",
    "title": "Search",
    "section": "Frontier Expansion",
    "text": "Frontier Expansion"
  },
  {
    "objectID": "4511/02/02.html#frontier-expansion-1",
    "href": "4511/02/02.html#frontier-expansion-1",
    "title": "Search",
    "section": "Frontier Expansion",
    "text": "Frontier Expansion\n\nFrontier: nodes “currently” expanded\n\nIf no frontier node is goal, need to add to frontier\nHow?\n\nCan we have cycles?\n\nHow do we deal with cycles?"
  },
  {
    "objectID": "4511/02/02.html#queues-searches",
    "href": "4511/02/02.html#queues-searches",
    "title": "Search",
    "section": "Queues & Searches",
    "text": "Queues & Searches\n\nPriority Queues\n\nBest-First Search\nUniform-Cost Search1\n\nFIFO Queues\n\nBreadth-First Search\n\nLIFO Queues2\n\nDepth-First Search\n\n\nAlso known as “Dijkstra’s Algorithm,” because it is Dijkstra’s AlgorithmAlso known as “stacks,” because they are stacks."
  },
  {
    "objectID": "4511/02/02.html#search-features",
    "href": "4511/02/02.html#search-features",
    "title": "Search",
    "section": "Search Features",
    "text": "Search Features\n\nCompleteness\n\nIf there is a solution, will we find it?\n\nOptimality\n\nWill we find the best solution?\n\nTime complexity\nMemory complexity"
  },
  {
    "objectID": "4511/02/02.html#breadth-first-search",
    "href": "4511/02/02.html#breadth-first-search",
    "title": "Search",
    "section": "Breadth-First Search",
    "text": "Breadth-First Search\n\nFIFO Queue\nComplete\nOptimal\n\\(O(b^d)\\)\nNice features for equal-weight arcs:\n\nLowest-cost path first\n\\(reached\\) collection can be a set"
  },
  {
    "objectID": "4511/02/02.html#breadth-first-search-1",
    "href": "4511/02/02.html#breadth-first-search-1",
    "title": "Search",
    "section": "Breadth-First Search",
    "text": "Breadth-First Search"
  },
  {
    "objectID": "4511/02/02.html#uniform-cost-search",
    "href": "4511/02/02.html#uniform-cost-search",
    "title": "Search",
    "section": "Uniform-Cost Search",
    "text": "Uniform-Cost Search\nNon-uniform costs \\(\\rightarrow\\) BFS inappropriate."
  },
  {
    "objectID": "4511/02/02.html#depth-first-search",
    "href": "4511/02/02.html#depth-first-search",
    "title": "Search",
    "section": "Depth-First Search",
    "text": "Depth-First Search\n\n“Family” of searches\nLIFO stack\nProblems?"
  },
  {
    "objectID": "4511/02/02.html#uninformed-search-variants",
    "href": "4511/02/02.html#uninformed-search-variants",
    "title": "Search",
    "section": "Uninformed Search Variants",
    "text": "Uninformed Search Variants\n\nDepth-Limited Search\n\nFail if depth limit reached (why?)\n\nIterative deepening\n\nvs. Breadth-First Search\n\nBidirectional Search"
  },
  {
    "objectID": "4511/02/02.html#how-to-choose",
    "href": "4511/02/02.html#how-to-choose",
    "title": "Search",
    "section": "How to Choose?",
    "text": "How to Choose?\n\nThink about when the searches “fail”\nThink about complexity\nDo we need an optimal solution?\n\nAre we looking for “any” solution"
  },
  {
    "objectID": "4511/02/02.html#it-is-possible-to-know-things",
    "href": "4511/02/02.html#it-is-possible-to-know-things",
    "title": "Search",
    "section": "It Is Possible To Know Things",
    "text": "It Is Possible To Know Things\n😌"
  },
  {
    "objectID": "4511/02/02.html#it-is-possible-to-know-things-1",
    "href": "4511/02/02.html#it-is-possible-to-know-things-1",
    "title": "Search",
    "section": "It Is Possible To Know Things",
    "text": "It Is Possible To Know Things"
  },
  {
    "objectID": "4511/02/02.html#heuristics",
    "href": "4511/02/02.html#heuristics",
    "title": "Search",
    "section": "Heuristics",
    "text": "Heuristics\nheuristic - adj - Serving to discover or find out.1\n\nWe know things about the problem\nThese things are external to the graph/tree structure\n\nWe could model the problem differently\nWe can use the information directly\n\n\nWebster’s, 1913"
  },
  {
    "objectID": "4511/02/02.html#best-first-search-reprise",
    "href": "4511/02/02.html#best-first-search-reprise",
    "title": "Search",
    "section": "Best-First Search (reprise)",
    "text": "Best-First Search (reprise)"
  },
  {
    "objectID": "4511/02/02.html#greedy-best-first-search",
    "href": "4511/02/02.html#greedy-best-first-search",
    "title": "Search",
    "section": "Greedy Best-First Search",
    "text": "Greedy Best-First Search\n\nHeuristic \\(h(n)\\)\n\n\\(n\\) is the search-tree node\n\\(h(n)\\) estimates cost from \\(n\\) to goal\n\nBest-first search: \\(f(n)\\) orders priority queue\n\nUse \\(f(n) = h(n)\\)\n\nComplete\nNo optimality guarantee\n\n(expected)"
  },
  {
    "objectID": "4511/02/02.html#a-search",
    "href": "4511/02/02.html#a-search",
    "title": "Search",
    "section": "A* Search",
    "text": "A* Search\n\nInclude path-cost \\(g(n)\\)\n\n\\(f(n) = g(n) + h(n)\\)\n\n\n\n\n\n\nComplete (always)\nOptimal (sometimes)\nPainful \\(O(b^m)\\) time and space complexity"
  },
  {
    "objectID": "4511/02/02.html#choosing-heuristics",
    "href": "4511/02/02.html#choosing-heuristics",
    "title": "Search",
    "section": "Choosing Heuristics",
    "text": "Choosing Heuristics\n\nRecall: \\(h(n)\\) estimates cost from \\(n\\) to goal\n\n\n\n\n\nAdmissibility\nConsistency"
  },
  {
    "objectID": "4511/02/02.html#choosing-heuristics-1",
    "href": "4511/02/02.html#choosing-heuristics-1",
    "title": "Search",
    "section": "Choosing Heuristics",
    "text": "Choosing Heuristics\n\nAdmissibility\n\nNever overestimates cost from \\(n\\) to goal\nCost-optimal!\n\nConsistency\n\n\\(h(n) \\leq c(n, a, n') + h(n')\\)\n\\(n'\\) successors of \\(n\\)\n\\(c(n, a, n')\\) cost from \\(n\\) to \\(n'\\) given action \\(a\\)"
  },
  {
    "objectID": "4511/02/02.html#consistency",
    "href": "4511/02/02.html#consistency",
    "title": "Search",
    "section": "Consistency",
    "text": "Consistency\n\nConsistent heuristics are admissible\n\nInverse not necessarily true\n\nAlways reach each state on optimal path\nImplications for inconsistent heuristic?"
  },
  {
    "objectID": "4511/02/02.html#is-optimality-desirable",
    "href": "4511/02/02.html#is-optimality-desirable",
    "title": "Search",
    "section": "Is Optimality Desirable?",
    "text": "Is Optimality Desirable?"
  },
  {
    "objectID": "4511/02/02.html#is-optimality-desirable-1",
    "href": "4511/02/02.html#is-optimality-desirable-1",
    "title": "Search",
    "section": "Is Optimality Desirable?",
    "text": "Is Optimality Desirable?\n\nYes"
  },
  {
    "objectID": "4511/02/02.html#is-optimality-desirable-2",
    "href": "4511/02/02.html#is-optimality-desirable-2",
    "title": "Search",
    "section": "Is Optimality Desirable?",
    "text": "Is Optimality Desirable?\n\nYes, but it isn’t always feasible\n\nA* search still exponentially complex in solution length\nOptimality is never guaranteed “inexpensively”\n\nWe need strategies for “good enough” solutions"
  },
  {
    "objectID": "4511/02/02.html#satisficing",
    "href": "4511/02/02.html#satisficing",
    "title": "Search",
    "section": "Satisficing",
    "text": "Satisficing\n\nsatisfy - verb - To give satisfaction; to afford gratification; to leave nothing to be desired.1\n\n\nsuffice - verb - To be enough, or sufficient; to meet the need (of anything)2\n\nWebster’s, 1913Webster’s, 1913"
  },
  {
    "objectID": "4511/02/02.html#weighted-a-search",
    "href": "4511/02/02.html#weighted-a-search",
    "title": "Search",
    "section": "Weighted A* Search",
    "text": "Weighted A* Search\n\nGreedy: \\(f(n) = h(n)\\)\nA*: \\(f(n) = h(n) + g(n)\\)\nUniform-Cost Search: \\(f(n) = g(n)\\)\n\n…\n\nWeighted A* Search: \\(f(n) = W\\cdot h(n) + g(n)\\)\n\nWeight \\(W &gt; 1\\)"
  },
  {
    "objectID": "4511/02/02.html#reducing-complexity",
    "href": "4511/02/02.html#reducing-complexity",
    "title": "Search",
    "section": "Reducing Complexity",
    "text": "Reducing Complexity\n\nFrontier Management\nElimination of \\(reached\\) collection\n\nReference counts\nHow else?\n\n\n\n\n\nOther searches"
  },
  {
    "objectID": "4511/02/02.html#iterative-deepening-a-search",
    "href": "4511/02/02.html#iterative-deepening-a-search",
    "title": "Search",
    "section": "Iterative-Deepening A* Search",
    "text": "Iterative-Deepening A* Search\n\n“IDA*” Search\n\nSimilar to Iterative Deepening with Depth-First Search\n\nDFS uses depth cutoff\nIDA* uses \\(h(n) + g(n)\\) cutoff with DFS\nOnce cutoff breached, new cutoff:\n\nTypically next-largest \\(h(n) + g(n)\\)\n\n\\(O(b^m)\\) time complexity 😔\n\\(O(d)\\) space complexity1 😌\n\n\n\nThis is slightly complicated based on heuristic branching factor \\(b_h\\)."
  },
  {
    "objectID": "4511/02/02.html#beam-search",
    "href": "4511/02/02.html#beam-search",
    "title": "Search",
    "section": "Beam Search",
    "text": "Beam Search\n\nBest-First Search:\n\nFrontier is all expanded nodes\n\nBeam Search:\n\n\\(k\\) “best” nodes are kept on frontier\n\nOthers discarded\n\nAlt: all nodes within \\(\\delta\\) of best node\nNot Optimal\nNot Complete"
  },
  {
    "objectID": "4511/02/02.html#recursive-best-first-search-rbfs",
    "href": "4511/02/02.html#recursive-best-first-search-rbfs",
    "title": "Search",
    "section": "Recursive Best-First Search (RBFS)",
    "text": "Recursive Best-First Search (RBFS)\n\nNo \\(reached\\) table is kept\nSecond-best node \\(f(n)\\) retained\n\nSearch from each node cannot exceed this limit\nIf exceeded, recursion “backs up” to previous node\n\nMemory-efficient\n\nCan “cycle” between branches"
  },
  {
    "objectID": "4511/02/02.html#recursive-best-first-search-rbfs-1",
    "href": "4511/02/02.html#recursive-best-first-search-rbfs-1",
    "title": "Search",
    "section": "Recursive Best-First Search (RBFS)",
    "text": "Recursive Best-First Search (RBFS)"
  },
  {
    "objectID": "4511/02/02.html#heuristic-characteristics",
    "href": "4511/02/02.html#heuristic-characteristics",
    "title": "Search",
    "section": "Heuristic Characteristics",
    "text": "Heuristic Characteristics\n\nWhat makes a “good” heuristic?\n\nWe know about admissability and consistency\nWhat about performance?\n\nEffective branching factor\nEffective depth\n# of nodes expanded"
  },
  {
    "objectID": "4511/02/02.html#where-do-heuristics-come-from",
    "href": "4511/02/02.html#where-do-heuristics-come-from",
    "title": "Search",
    "section": "Where Do Heuristics Come From?",
    "text": "Where Do Heuristics Come From?\n\nIntuition\n\n“Just Be Really Smart”\n\nRelaxation\n\nThe problem is constrained\nRemove the constraint\n\nPre-computation\n\nSub problems\n\nLearning"
  },
  {
    "objectID": "4511/02/02.html#references",
    "href": "4511/02/02.html#references",
    "title": "Search",
    "section": "References",
    "text": "References\n\nStuart J. Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. 4th Edition, 2020.\nStanford CS231\nUC Berkeley CS188"
  }
]